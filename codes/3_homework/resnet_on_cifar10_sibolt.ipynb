{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsdKToFor69U"
   },
   "source": [
    "# Homework 3, exercise 2 - Residual Neural Network on CIFAR10\n",
    "\n",
    "In this exercise we implement a (slightly modified) ResNet as introduced in [this paper](https://arxiv.org/pdf/1512.03385.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VdY58D3KMZO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRuR6CcbsW8_"
   },
   "source": [
    "For this exercise it is recommended to use the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1576003485265,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "rhZQhrlxKSTK",
    "outputId": "080851ee-4233-4e39-e5ab-ecde4d88530a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwJz3i37UXsZ"
   },
   "source": [
    "### Load the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2310,
     "status": "ok",
     "timestamp": 1576005182727,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "e1WVamZiKSXR",
    "outputId": "3ad28be0-c0d3-48f8-de13-5bbdc49dd617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "c, w, h = 3, 32, 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfpdVQRbUg5p"
   },
   "source": [
    "## Exercise - Implement a Residual Block\n",
    "\n",
    "Residual neural networks mainly consist of components called Residual Blocks. One residual block can be expressed as **y** = *F*(**x**) + **x** where **x** and **y** are the input and output of the block, respectively. So the input **x** is added to the result of *F*(**x**) using a *skip connection*. In this exercise, *F* consists of:\n",
    "* a convolutional layer with `in_channels` input channels, `hidden_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n",
    "* a batch normalisation layer \n",
    "* ReLU activation\n",
    "* a convolutional layer with `hidden_channels` input channels, `out_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n",
    "* a batch normalisation layer\n",
    "\n",
    "After this the `skip_connection` is applied. If the dimensions of *F*(**x**) and **x** don't match an extra linear projection is applied to **x** so the dimensions do match. This has already been implemented for you. You only need to call it at the right place. \n",
    "Finally, a ReLU activation is applied on the output **y**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HK1qpjYwUFqh"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=(3,3), stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=(3,3), stride = 1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        if in_channels != out_channels:  # F(x) and x dimensions do not match! Define a projection for input x\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "        else:\n",
    "            self.skip_connection = lambda x: x  # The dimensions already match! No need to do a projection on x\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += self.skip_connection(residual)\n",
    "        x = self.relu(x)\n",
    "        return (x)\n",
    "    \n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1Y87D77cYX8"
   },
   "source": [
    "## Exercise - Implement a Residual Neural Network\n",
    "Now you can use the previously defined Residual Block to create your ResNet.\n",
    "\n",
    "The network consists of:\n",
    "* a convolutional layer with `in_channels` input channels, 64 output channels, a stride of 1, padding of 1 and no bias parameter,\n",
    "* a batch normalisation layer\n",
    "* ReLU activation\n",
    "* a max pooling layer with kernel size (3, 3), a stride of 2 and padding of 1,\n",
    "* eight residual blocks, with (64, 64, 128, 128, 256, 256, 512, 512) channels, respectively (see code below) \n",
    "* an average pooling layer over all feature maps (already present)\n",
    "* a dense layer to form the output distribution (already present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qVgN9lPKSeC"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,64, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.res_blocks = nn.ModuleList(\n",
    "            [\n",
    "             ResidualBlock(64, 64, 64),\n",
    "             ResidualBlock(64, 64, 64),\n",
    "         \n",
    "             ResidualBlock(64, 128, 128),\n",
    "             ResidualBlock(128, 128, 128),\n",
    "         \n",
    "             ResidualBlock(128, 256, 256),\n",
    "             ResidualBlock(256, 256, 256),\n",
    "\n",
    "             ResidualBlock(256, 512, 512),\n",
    "             ResidualBlock(512, 512, 512),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dense_layer = nn.Linear(512, out_size)\n",
    "    \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.res_blocks[0](x)\n",
    "        x = self.res_blocks[1](x)\n",
    "        x = self.res_blocks[2](x)\n",
    "        x = self.res_blocks[3](x)\n",
    "        x = self.res_blocks[4](x)\n",
    "        x = self.res_blocks[5](x)\n",
    "        x = self.res_blocks[6](x)\n",
    "        x = self.res_blocks[7](x)\n",
    "        \n",
    "        x = F.avg_pool2d(x, x.shape[2:])\n",
    "    \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dense_layer(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZ9ny4USgNAu"
   },
   "source": [
    "### Initialize the network, Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIofWmkrT6Oh"
   },
   "outputs": [],
   "source": [
    "net = ResNet(c, len(classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojw0pS0dgZHX"
   },
   "source": [
    "## Exercise - Train/evaluate the network\n",
    "Train the network you built using the code below. Add the following answers in your report:\n",
    "* What test accuracy were you able to get?\n",
    "* How many layers does your network have? (counting only convolutional and dense layers)\n",
    "* Why do the skip connections help for training deep neural networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IcG_bfjoT7Dx",
    "outputId": "a5280aa9-5f1c-4867-b0e8-8444b5795ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, time: 0.283s, loss: 2.451, train accuracy: 0.055\n",
      "epoch: 0, time: 5.644s, loss: 1.931, train accuracy: 0.289\n",
      "epoch: 0, time: 11.135s, loss: 1.738, train accuracy: 0.359\n",
      "epoch: 0, time: 16.427s, loss: 1.636, train accuracy: 0.359\n",
      "epoch: 0, time: 21.653s, loss: 1.754, train accuracy: 0.289\n",
      "epoch: 0, time: 26.913s, loss: 1.699, train accuracy: 0.359\n",
      "epoch: 0, time: 32.210s, loss: 1.502, train accuracy: 0.430\n",
      "epoch: 0, time: 37.531s, loss: 1.512, train accuracy: 0.461\n",
      "epoch: 0, time: 42.820s, loss: 1.581, train accuracy: 0.367\n",
      "epoch: 0, time: 48.069s, loss: 1.346, train accuracy: 0.453\n",
      "epoch: 0, time: 53.309s, loss: 1.525, train accuracy: 0.469\n",
      "epoch: 0, time: 58.550s, loss: 1.527, train accuracy: 0.469\n",
      "epoch: 0, time: 63.797s, loss: 1.385, train accuracy: 0.516\n",
      "epoch: 0, time: 69.048s, loss: 1.406, train accuracy: 0.398\n",
      "epoch: 0, time: 74.301s, loss: 1.341, train accuracy: 0.516\n",
      "epoch: 0, time: 79.558s, loss: 1.277, train accuracy: 0.555\n",
      "epoch: 0, time: 84.810s, loss: 1.497, train accuracy: 0.477\n",
      "epoch: 0, time: 90.061s, loss: 1.468, train accuracy: 0.461\n",
      "epoch: 0, time: 95.315s, loss: 1.315, train accuracy: 0.500\n",
      "epoch: 0, time: 100.581s, loss: 1.304, train accuracy: 0.453\n",
      "Accuracy on the test set: 0.454\n",
      "epoch: 1, time: 110.213s, loss: 1.300, train accuracy: 0.539\n",
      "epoch: 1, time: 115.471s, loss: 1.217, train accuracy: 0.555\n",
      "epoch: 1, time: 120.729s, loss: 1.318, train accuracy: 0.547\n",
      "epoch: 1, time: 125.991s, loss: 1.433, train accuracy: 0.469\n",
      "epoch: 1, time: 131.247s, loss: 1.315, train accuracy: 0.516\n",
      "epoch: 1, time: 136.513s, loss: 1.311, train accuracy: 0.547\n",
      "epoch: 1, time: 141.770s, loss: 1.225, train accuracy: 0.578\n",
      "epoch: 1, time: 147.031s, loss: 1.281, train accuracy: 0.555\n",
      "epoch: 1, time: 152.292s, loss: 1.231, train accuracy: 0.555\n",
      "epoch: 1, time: 157.555s, loss: 1.116, train accuracy: 0.500\n",
      "epoch: 1, time: 162.864s, loss: 1.111, train accuracy: 0.578\n",
      "epoch: 1, time: 168.125s, loss: 1.160, train accuracy: 0.594\n",
      "epoch: 1, time: 173.392s, loss: 1.214, train accuracy: 0.547\n",
      "epoch: 1, time: 178.649s, loss: 1.173, train accuracy: 0.547\n",
      "epoch: 1, time: 183.910s, loss: 1.247, train accuracy: 0.547\n",
      "epoch: 1, time: 189.167s, loss: 1.182, train accuracy: 0.578\n",
      "epoch: 1, time: 194.425s, loss: 1.136, train accuracy: 0.578\n",
      "epoch: 1, time: 199.688s, loss: 1.174, train accuracy: 0.586\n",
      "epoch: 1, time: 204.949s, loss: 0.936, train accuracy: 0.672\n",
      "epoch: 1, time: 210.208s, loss: 1.163, train accuracy: 0.602\n",
      "Accuracy on the test set: 0.588\n",
      "epoch: 2, time: 219.872s, loss: 1.039, train accuracy: 0.625\n",
      "epoch: 2, time: 225.274s, loss: 1.153, train accuracy: 0.594\n",
      "epoch: 2, time: 230.533s, loss: 1.065, train accuracy: 0.656\n",
      "epoch: 2, time: 235.791s, loss: 0.933, train accuracy: 0.695\n",
      "epoch: 2, time: 241.045s, loss: 1.159, train accuracy: 0.586\n",
      "epoch: 2, time: 246.307s, loss: 0.974, train accuracy: 0.633\n",
      "epoch: 2, time: 251.567s, loss: 1.085, train accuracy: 0.578\n",
      "epoch: 2, time: 256.825s, loss: 1.124, train accuracy: 0.555\n",
      "epoch: 2, time: 262.083s, loss: 1.156, train accuracy: 0.578\n",
      "epoch: 2, time: 267.339s, loss: 0.903, train accuracy: 0.602\n",
      "epoch: 2, time: 272.586s, loss: 1.212, train accuracy: 0.602\n",
      "epoch: 2, time: 277.841s, loss: 0.994, train accuracy: 0.648\n",
      "epoch: 2, time: 283.162s, loss: 1.019, train accuracy: 0.617\n",
      "epoch: 2, time: 288.416s, loss: 1.257, train accuracy: 0.586\n",
      "epoch: 2, time: 293.677s, loss: 1.053, train accuracy: 0.648\n",
      "epoch: 2, time: 298.939s, loss: 0.963, train accuracy: 0.648\n",
      "epoch: 2, time: 304.209s, loss: 1.074, train accuracy: 0.602\n",
      "epoch: 2, time: 309.472s, loss: 1.182, train accuracy: 0.609\n",
      "epoch: 2, time: 314.729s, loss: 1.017, train accuracy: 0.617\n",
      "epoch: 2, time: 319.992s, loss: 1.012, train accuracy: 0.664\n",
      "Accuracy on the test set: 0.586\n",
      "epoch: 3, time: 329.616s, loss: 0.944, train accuracy: 0.648\n",
      "epoch: 3, time: 334.872s, loss: 0.994, train accuracy: 0.625\n",
      "epoch: 3, time: 340.452s, loss: 0.976, train accuracy: 0.672\n",
      "epoch: 3, time: 346.052s, loss: 0.951, train accuracy: 0.656\n",
      "epoch: 3, time: 351.375s, loss: 0.770, train accuracy: 0.734\n",
      "epoch: 3, time: 356.599s, loss: 1.002, train accuracy: 0.656\n",
      "epoch: 3, time: 361.816s, loss: 0.948, train accuracy: 0.695\n",
      "epoch: 3, time: 367.053s, loss: 1.020, train accuracy: 0.648\n",
      "epoch: 3, time: 372.287s, loss: 1.070, train accuracy: 0.641\n",
      "epoch: 3, time: 377.520s, loss: 0.947, train accuracy: 0.641\n",
      "epoch: 3, time: 382.741s, loss: 0.882, train accuracy: 0.656\n",
      "epoch: 3, time: 387.979s, loss: 0.930, train accuracy: 0.641\n",
      "epoch: 3, time: 393.199s, loss: 0.900, train accuracy: 0.703\n",
      "epoch: 3, time: 398.437s, loss: 0.977, train accuracy: 0.633\n",
      "epoch: 3, time: 403.731s, loss: 0.814, train accuracy: 0.727\n",
      "epoch: 3, time: 408.953s, loss: 1.013, train accuracy: 0.672\n",
      "epoch: 3, time: 414.190s, loss: 0.980, train accuracy: 0.641\n",
      "epoch: 3, time: 419.427s, loss: 0.839, train accuracy: 0.680\n",
      "epoch: 3, time: 424.661s, loss: 0.981, train accuracy: 0.672\n",
      "epoch: 3, time: 429.884s, loss: 0.704, train accuracy: 0.789\n",
      "Accuracy on the test set: 0.626\n",
      "epoch: 4, time: 439.497s, loss: 0.729, train accuracy: 0.734\n",
      "epoch: 4, time: 444.729s, loss: 0.852, train accuracy: 0.703\n",
      "epoch: 4, time: 449.944s, loss: 0.959, train accuracy: 0.680\n",
      "epoch: 4, time: 455.180s, loss: 0.942, train accuracy: 0.695\n",
      "epoch: 4, time: 460.400s, loss: 0.977, train accuracy: 0.617\n",
      "epoch: 4, time: 465.637s, loss: 0.834, train accuracy: 0.742\n",
      "epoch: 4, time: 470.871s, loss: 0.814, train accuracy: 0.719\n",
      "epoch: 4, time: 476.100s, loss: 0.885, train accuracy: 0.680\n",
      "epoch: 4, time: 481.333s, loss: 1.014, train accuracy: 0.641\n",
      "epoch: 4, time: 486.565s, loss: 0.748, train accuracy: 0.727\n",
      "epoch: 4, time: 491.800s, loss: 0.891, train accuracy: 0.711\n",
      "epoch: 4, time: 497.036s, loss: 0.916, train accuracy: 0.734\n",
      "epoch: 4, time: 502.254s, loss: 1.059, train accuracy: 0.648\n",
      "epoch: 4, time: 507.489s, loss: 0.901, train accuracy: 0.664\n",
      "epoch: 4, time: 512.707s, loss: 0.692, train accuracy: 0.789\n",
      "epoch: 4, time: 517.941s, loss: 0.870, train accuracy: 0.711\n",
      "epoch: 4, time: 523.221s, loss: 0.824, train accuracy: 0.695\n",
      "epoch: 4, time: 528.460s, loss: 0.714, train accuracy: 0.734\n",
      "epoch: 4, time: 533.676s, loss: 0.864, train accuracy: 0.711\n",
      "epoch: 4, time: 538.914s, loss: 0.776, train accuracy: 0.727\n",
      "Accuracy on the test set: 0.683\n",
      "epoch: 5, time: 548.524s, loss: 0.891, train accuracy: 0.750\n",
      "epoch: 5, time: 553.761s, loss: 0.820, train accuracy: 0.719\n",
      "epoch: 5, time: 558.997s, loss: 0.732, train accuracy: 0.750\n",
      "epoch: 5, time: 564.233s, loss: 0.808, train accuracy: 0.750\n",
      "epoch: 5, time: 569.451s, loss: 0.704, train accuracy: 0.766\n",
      "epoch: 5, time: 574.685s, loss: 0.794, train accuracy: 0.750\n",
      "epoch: 5, time: 579.922s, loss: 0.811, train accuracy: 0.703\n",
      "epoch: 5, time: 585.161s, loss: 0.871, train accuracy: 0.742\n",
      "epoch: 5, time: 590.411s, loss: 0.707, train accuracy: 0.727\n",
      "epoch: 5, time: 595.681s, loss: 0.695, train accuracy: 0.797\n",
      "epoch: 5, time: 600.959s, loss: 0.718, train accuracy: 0.773\n",
      "epoch: 5, time: 606.198s, loss: 0.633, train accuracy: 0.766\n",
      "epoch: 5, time: 611.445s, loss: 0.589, train accuracy: 0.805\n",
      "epoch: 5, time: 616.695s, loss: 0.768, train accuracy: 0.727\n",
      "epoch: 5, time: 621.934s, loss: 0.766, train accuracy: 0.766\n",
      "epoch: 5, time: 627.474s, loss: 0.715, train accuracy: 0.766\n",
      "epoch: 5, time: 632.689s, loss: 0.743, train accuracy: 0.742\n",
      "epoch: 5, time: 637.926s, loss: 0.874, train accuracy: 0.672\n",
      "epoch: 5, time: 643.208s, loss: 0.780, train accuracy: 0.711\n",
      "epoch: 5, time: 648.427s, loss: 0.655, train accuracy: 0.734\n",
      "Accuracy on the test set: 0.722\n",
      "epoch: 6, time: 658.033s, loss: 0.944, train accuracy: 0.648\n",
      "epoch: 6, time: 663.245s, loss: 0.711, train accuracy: 0.758\n",
      "epoch: 6, time: 668.469s, loss: 0.640, train accuracy: 0.750\n",
      "epoch: 6, time: 673.702s, loss: 0.730, train accuracy: 0.727\n",
      "epoch: 6, time: 678.935s, loss: 0.824, train accuracy: 0.719\n",
      "epoch: 6, time: 684.148s, loss: 0.716, train accuracy: 0.750\n",
      "epoch: 6, time: 689.363s, loss: 0.855, train accuracy: 0.695\n",
      "epoch: 6, time: 694.585s, loss: 0.599, train accuracy: 0.750\n",
      "epoch: 6, time: 699.815s, loss: 0.704, train accuracy: 0.688\n",
      "epoch: 6, time: 705.047s, loss: 0.829, train accuracy: 0.719\n",
      "epoch: 6, time: 710.270s, loss: 0.747, train accuracy: 0.734\n",
      "epoch: 6, time: 715.508s, loss: 0.804, train accuracy: 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, time: 720.742s, loss: 0.646, train accuracy: 0.766\n",
      "epoch: 6, time: 725.963s, loss: 0.840, train accuracy: 0.727\n",
      "epoch: 6, time: 731.194s, loss: 0.660, train accuracy: 0.805\n",
      "epoch: 6, time: 736.427s, loss: 0.611, train accuracy: 0.781\n",
      "epoch: 6, time: 741.648s, loss: 0.803, train accuracy: 0.727\n",
      "epoch: 6, time: 746.863s, loss: 0.646, train accuracy: 0.797\n",
      "epoch: 6, time: 752.077s, loss: 0.757, train accuracy: 0.750\n",
      "epoch: 6, time: 757.291s, loss: 0.781, train accuracy: 0.742\n",
      "Accuracy on the test set: 0.713\n",
      "epoch: 7, time: 766.960s, loss: 0.521, train accuracy: 0.852\n",
      "epoch: 7, time: 772.185s, loss: 0.691, train accuracy: 0.742\n",
      "epoch: 7, time: 777.414s, loss: 0.646, train accuracy: 0.750\n",
      "epoch: 7, time: 782.633s, loss: 0.677, train accuracy: 0.789\n",
      "epoch: 7, time: 787.868s, loss: 0.706, train accuracy: 0.750\n",
      "epoch: 7, time: 793.103s, loss: 0.574, train accuracy: 0.812\n",
      "epoch: 7, time: 798.342s, loss: 0.635, train accuracy: 0.781\n",
      "epoch: 7, time: 803.560s, loss: 0.667, train accuracy: 0.734\n",
      "epoch: 7, time: 808.779s, loss: 0.777, train accuracy: 0.773\n",
      "epoch: 7, time: 814.014s, loss: 0.546, train accuracy: 0.812\n",
      "epoch: 7, time: 819.230s, loss: 0.630, train accuracy: 0.797\n",
      "epoch: 7, time: 824.464s, loss: 0.655, train accuracy: 0.773\n",
      "epoch: 7, time: 829.680s, loss: 0.701, train accuracy: 0.758\n",
      "epoch: 7, time: 834.905s, loss: 0.469, train accuracy: 0.812\n",
      "epoch: 7, time: 840.133s, loss: 0.696, train accuracy: 0.703\n",
      "epoch: 7, time: 845.366s, loss: 0.682, train accuracy: 0.750\n",
      "epoch: 7, time: 850.584s, loss: 0.571, train accuracy: 0.789\n",
      "epoch: 7, time: 855.798s, loss: 0.707, train accuracy: 0.711\n",
      "epoch: 7, time: 861.038s, loss: 0.648, train accuracy: 0.750\n",
      "epoch: 7, time: 866.274s, loss: 0.774, train accuracy: 0.734\n",
      "Accuracy on the test set: 0.746\n",
      "epoch: 8, time: 875.909s, loss: 0.721, train accuracy: 0.758\n",
      "epoch: 8, time: 881.182s, loss: 0.546, train accuracy: 0.844\n",
      "epoch: 8, time: 886.443s, loss: 0.724, train accuracy: 0.734\n",
      "epoch: 8, time: 891.680s, loss: 0.659, train accuracy: 0.742\n",
      "epoch: 8, time: 896.913s, loss: 0.558, train accuracy: 0.781\n",
      "epoch: 8, time: 902.153s, loss: 0.477, train accuracy: 0.836\n",
      "epoch: 8, time: 907.381s, loss: 0.479, train accuracy: 0.852\n",
      "epoch: 8, time: 912.627s, loss: 0.581, train accuracy: 0.773\n",
      "epoch: 8, time: 917.871s, loss: 0.677, train accuracy: 0.766\n",
      "epoch: 8, time: 923.104s, loss: 0.507, train accuracy: 0.828\n",
      "epoch: 8, time: 928.348s, loss: 0.525, train accuracy: 0.797\n",
      "epoch: 8, time: 933.579s, loss: 0.517, train accuracy: 0.781\n",
      "epoch: 8, time: 938.794s, loss: 0.531, train accuracy: 0.805\n",
      "epoch: 8, time: 944.016s, loss: 0.740, train accuracy: 0.758\n",
      "epoch: 8, time: 949.247s, loss: 0.585, train accuracy: 0.766\n",
      "epoch: 8, time: 954.462s, loss: 0.719, train accuracy: 0.766\n",
      "epoch: 8, time: 959.673s, loss: 0.463, train accuracy: 0.836\n",
      "epoch: 8, time: 964.894s, loss: 0.649, train accuracy: 0.773\n",
      "epoch: 8, time: 970.127s, loss: 0.490, train accuracy: 0.805\n",
      "epoch: 8, time: 975.342s, loss: 0.604, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.761\n",
      "epoch: 9, time: 984.952s, loss: 0.557, train accuracy: 0.781\n",
      "epoch: 9, time: 990.170s, loss: 0.509, train accuracy: 0.812\n",
      "epoch: 9, time: 995.400s, loss: 0.487, train accuracy: 0.812\n",
      "epoch: 9, time: 1000.644s, loss: 0.667, train accuracy: 0.750\n",
      "epoch: 9, time: 1005.908s, loss: 0.677, train accuracy: 0.758\n",
      "epoch: 9, time: 1011.134s, loss: 0.393, train accuracy: 0.867\n",
      "epoch: 9, time: 1016.347s, loss: 0.513, train accuracy: 0.820\n",
      "epoch: 9, time: 1021.562s, loss: 0.575, train accuracy: 0.812\n",
      "epoch: 9, time: 1026.784s, loss: 0.545, train accuracy: 0.836\n",
      "epoch: 9, time: 1032.015s, loss: 0.560, train accuracy: 0.789\n",
      "epoch: 9, time: 1037.252s, loss: 0.494, train accuracy: 0.836\n",
      "epoch: 9, time: 1042.468s, loss: 0.551, train accuracy: 0.805\n",
      "epoch: 9, time: 1047.684s, loss: 0.613, train accuracy: 0.797\n",
      "epoch: 9, time: 1052.903s, loss: 0.808, train accuracy: 0.773\n",
      "epoch: 9, time: 1058.129s, loss: 0.593, train accuracy: 0.812\n",
      "epoch: 9, time: 1063.355s, loss: 0.675, train accuracy: 0.766\n",
      "epoch: 9, time: 1068.591s, loss: 0.563, train accuracy: 0.812\n",
      "epoch: 9, time: 1073.815s, loss: 0.649, train accuracy: 0.766\n",
      "epoch: 9, time: 1079.045s, loss: 0.526, train accuracy: 0.797\n",
      "epoch: 9, time: 1084.258s, loss: 0.501, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.733\n",
      "epoch: 10, time: 1093.870s, loss: 0.525, train accuracy: 0.812\n",
      "epoch: 10, time: 1099.104s, loss: 0.534, train accuracy: 0.820\n",
      "epoch: 10, time: 1104.322s, loss: 0.481, train accuracy: 0.820\n",
      "epoch: 10, time: 1109.558s, loss: 0.522, train accuracy: 0.797\n",
      "epoch: 10, time: 1114.771s, loss: 0.602, train accuracy: 0.797\n",
      "epoch: 10, time: 1120.031s, loss: 0.461, train accuracy: 0.867\n",
      "epoch: 10, time: 1125.290s, loss: 0.355, train accuracy: 0.859\n",
      "epoch: 10, time: 1130.513s, loss: 0.489, train accuracy: 0.836\n",
      "epoch: 10, time: 1135.745s, loss: 0.530, train accuracy: 0.812\n",
      "epoch: 10, time: 1140.960s, loss: 0.522, train accuracy: 0.797\n",
      "epoch: 10, time: 1146.173s, loss: 0.517, train accuracy: 0.820\n",
      "epoch: 10, time: 1151.389s, loss: 0.535, train accuracy: 0.820\n",
      "epoch: 10, time: 1156.625s, loss: 0.628, train accuracy: 0.758\n",
      "epoch: 10, time: 1161.843s, loss: 0.416, train accuracy: 0.852\n",
      "epoch: 10, time: 1167.060s, loss: 0.518, train accuracy: 0.789\n",
      "epoch: 10, time: 1172.292s, loss: 0.550, train accuracy: 0.805\n",
      "epoch: 10, time: 1177.510s, loss: 0.651, train accuracy: 0.797\n",
      "epoch: 10, time: 1182.724s, loss: 0.561, train accuracy: 0.859\n",
      "epoch: 10, time: 1187.964s, loss: 0.602, train accuracy: 0.812\n",
      "epoch: 10, time: 1193.200s, loss: 0.467, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.784\n",
      "epoch: 11, time: 1202.808s, loss: 0.519, train accuracy: 0.797\n",
      "epoch: 11, time: 1208.033s, loss: 0.538, train accuracy: 0.836\n",
      "epoch: 11, time: 1213.262s, loss: 0.564, train accuracy: 0.797\n",
      "epoch: 11, time: 1218.475s, loss: 0.682, train accuracy: 0.766\n",
      "epoch: 11, time: 1223.714s, loss: 0.555, train accuracy: 0.805\n",
      "epoch: 11, time: 1228.932s, loss: 0.305, train accuracy: 0.898\n",
      "epoch: 11, time: 1234.153s, loss: 0.602, train accuracy: 0.766\n",
      "epoch: 11, time: 1239.384s, loss: 0.411, train accuracy: 0.844\n",
      "epoch: 11, time: 1244.666s, loss: 0.553, train accuracy: 0.797\n",
      "epoch: 11, time: 1249.884s, loss: 0.475, train accuracy: 0.836\n",
      "epoch: 11, time: 1255.102s, loss: 0.513, train accuracy: 0.828\n",
      "epoch: 11, time: 1260.335s, loss: 0.608, train accuracy: 0.797\n",
      "epoch: 11, time: 1265.552s, loss: 0.509, train accuracy: 0.836\n",
      "epoch: 11, time: 1270.767s, loss: 0.510, train accuracy: 0.828\n",
      "epoch: 11, time: 1275.988s, loss: 0.591, train accuracy: 0.805\n",
      "epoch: 11, time: 1281.218s, loss: 0.502, train accuracy: 0.828\n",
      "epoch: 11, time: 1286.435s, loss: 0.504, train accuracy: 0.805\n",
      "epoch: 11, time: 1291.655s, loss: 0.435, train accuracy: 0.891\n",
      "epoch: 11, time: 1296.886s, loss: 0.388, train accuracy: 0.883\n",
      "epoch: 11, time: 1302.100s, loss: 0.590, train accuracy: 0.836\n",
      "Accuracy on the test set: 0.795\n",
      "epoch: 12, time: 1311.709s, loss: 0.502, train accuracy: 0.836\n",
      "epoch: 12, time: 1316.923s, loss: 0.417, train accuracy: 0.859\n",
      "epoch: 12, time: 1322.140s, loss: 0.474, train accuracy: 0.797\n",
      "epoch: 12, time: 1327.355s, loss: 0.424, train accuracy: 0.859\n",
      "epoch: 12, time: 1332.568s, loss: 0.470, train accuracy: 0.828\n",
      "epoch: 12, time: 1337.806s, loss: 0.448, train accuracy: 0.836\n",
      "epoch: 12, time: 1343.019s, loss: 0.431, train accuracy: 0.812\n",
      "epoch: 12, time: 1348.235s, loss: 0.482, train accuracy: 0.875\n",
      "epoch: 12, time: 1353.456s, loss: 0.431, train accuracy: 0.859\n",
      "epoch: 12, time: 1358.687s, loss: 0.490, train accuracy: 0.852\n",
      "epoch: 12, time: 1363.969s, loss: 0.493, train accuracy: 0.805\n",
      "epoch: 12, time: 1369.183s, loss: 0.454, train accuracy: 0.844\n",
      "epoch: 12, time: 1374.404s, loss: 0.330, train accuracy: 0.914\n",
      "epoch: 12, time: 1379.637s, loss: 0.491, train accuracy: 0.836\n",
      "epoch: 12, time: 1384.854s, loss: 0.484, train accuracy: 0.852\n",
      "epoch: 12, time: 1390.071s, loss: 0.491, train accuracy: 0.844\n",
      "epoch: 12, time: 1395.284s, loss: 0.499, train accuracy: 0.812\n",
      "epoch: 12, time: 1400.520s, loss: 0.499, train accuracy: 0.805\n",
      "epoch: 12, time: 1405.734s, loss: 0.426, train accuracy: 0.844\n",
      "epoch: 12, time: 1410.971s, loss: 0.534, train accuracy: 0.805\n",
      "Accuracy on the test set: 0.778\n",
      "epoch: 13, time: 1420.582s, loss: 0.599, train accuracy: 0.766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, time: 1425.820s, loss: 0.374, train accuracy: 0.875\n",
      "epoch: 13, time: 1431.067s, loss: 0.425, train accuracy: 0.844\n",
      "epoch: 13, time: 1436.295s, loss: 0.489, train accuracy: 0.836\n",
      "epoch: 13, time: 1441.531s, loss: 0.409, train accuracy: 0.859\n",
      "epoch: 13, time: 1446.769s, loss: 0.564, train accuracy: 0.805\n",
      "epoch: 13, time: 1452.008s, loss: 0.737, train accuracy: 0.758\n",
      "epoch: 13, time: 1457.245s, loss: 0.721, train accuracy: 0.773\n",
      "epoch: 13, time: 1462.495s, loss: 0.563, train accuracy: 0.805\n",
      "epoch: 13, time: 1467.738s, loss: 0.362, train accuracy: 0.883\n",
      "epoch: 13, time: 1472.979s, loss: 0.530, train accuracy: 0.766\n",
      "epoch: 13, time: 1478.214s, loss: 0.382, train accuracy: 0.867\n",
      "epoch: 13, time: 1483.499s, loss: 0.599, train accuracy: 0.805\n",
      "epoch: 13, time: 1488.758s, loss: 0.476, train accuracy: 0.844\n",
      "epoch: 13, time: 1494.023s, loss: 0.459, train accuracy: 0.812\n",
      "epoch: 13, time: 1499.293s, loss: 0.423, train accuracy: 0.844\n",
      "epoch: 13, time: 1504.607s, loss: 0.548, train accuracy: 0.828\n",
      "epoch: 13, time: 1509.839s, loss: 0.388, train accuracy: 0.867\n",
      "epoch: 13, time: 1515.081s, loss: 0.428, train accuracy: 0.891\n",
      "epoch: 13, time: 1520.323s, loss: 0.334, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.797\n",
      "epoch: 14, time: 1529.947s, loss: 0.327, train accuracy: 0.875\n",
      "epoch: 14, time: 1535.181s, loss: 0.422, train accuracy: 0.859\n",
      "epoch: 14, time: 1540.424s, loss: 0.296, train accuracy: 0.883\n",
      "epoch: 14, time: 1545.653s, loss: 0.332, train accuracy: 0.906\n",
      "epoch: 14, time: 1550.870s, loss: 0.472, train accuracy: 0.828\n",
      "epoch: 14, time: 1556.106s, loss: 0.518, train accuracy: 0.820\n",
      "epoch: 14, time: 1561.362s, loss: 0.432, train accuracy: 0.852\n",
      "epoch: 14, time: 1566.602s, loss: 0.390, train accuracy: 0.875\n",
      "epoch: 14, time: 1571.842s, loss: 0.430, train accuracy: 0.867\n",
      "epoch: 14, time: 1577.086s, loss: 0.393, train accuracy: 0.875\n",
      "epoch: 14, time: 1582.320s, loss: 0.500, train accuracy: 0.828\n",
      "epoch: 14, time: 1587.572s, loss: 0.471, train accuracy: 0.859\n",
      "epoch: 14, time: 1592.814s, loss: 0.451, train accuracy: 0.844\n",
      "epoch: 14, time: 1598.032s, loss: 0.489, train accuracy: 0.805\n",
      "epoch: 14, time: 1603.321s, loss: 0.506, train accuracy: 0.812\n",
      "epoch: 14, time: 1608.559s, loss: 0.469, train accuracy: 0.828\n",
      "epoch: 14, time: 1613.801s, loss: 0.370, train accuracy: 0.867\n",
      "epoch: 14, time: 1619.022s, loss: 0.352, train accuracy: 0.844\n",
      "epoch: 14, time: 1624.258s, loss: 0.301, train accuracy: 0.875\n",
      "epoch: 14, time: 1629.500s, loss: 0.433, train accuracy: 0.852\n",
      "Accuracy on the test set: 0.808\n",
      "epoch: 15, time: 1639.128s, loss: 0.331, train accuracy: 0.883\n",
      "epoch: 15, time: 1644.363s, loss: 0.337, train accuracy: 0.914\n",
      "epoch: 15, time: 1649.589s, loss: 0.435, train accuracy: 0.844\n",
      "epoch: 15, time: 1654.827s, loss: 0.385, train accuracy: 0.875\n",
      "epoch: 15, time: 1660.054s, loss: 0.364, train accuracy: 0.891\n",
      "epoch: 15, time: 1665.314s, loss: 0.525, train accuracy: 0.812\n",
      "epoch: 15, time: 1670.552s, loss: 0.336, train accuracy: 0.883\n",
      "epoch: 15, time: 1675.797s, loss: 0.282, train accuracy: 0.898\n",
      "epoch: 15, time: 1681.029s, loss: 0.535, train accuracy: 0.812\n",
      "epoch: 15, time: 1686.264s, loss: 0.500, train accuracy: 0.852\n",
      "epoch: 15, time: 1691.485s, loss: 0.494, train accuracy: 0.820\n",
      "epoch: 15, time: 1696.724s, loss: 0.291, train accuracy: 0.914\n",
      "epoch: 15, time: 1701.955s, loss: 0.370, train accuracy: 0.883\n",
      "epoch: 15, time: 1707.191s, loss: 0.375, train accuracy: 0.875\n",
      "epoch: 15, time: 1712.430s, loss: 0.419, train accuracy: 0.852\n",
      "epoch: 15, time: 1717.669s, loss: 0.250, train accuracy: 0.906\n",
      "epoch: 15, time: 1722.949s, loss: 0.389, train accuracy: 0.852\n",
      "epoch: 15, time: 1728.197s, loss: 0.307, train accuracy: 0.898\n",
      "epoch: 15, time: 1733.444s, loss: 0.384, train accuracy: 0.883\n",
      "epoch: 15, time: 1738.683s, loss: 0.442, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.806\n",
      "epoch: 16, time: 1748.294s, loss: 0.349, train accuracy: 0.883\n",
      "epoch: 16, time: 1753.539s, loss: 0.375, train accuracy: 0.875\n",
      "epoch: 16, time: 1758.766s, loss: 0.334, train accuracy: 0.898\n",
      "epoch: 16, time: 1764.022s, loss: 0.437, train accuracy: 0.836\n",
      "epoch: 16, time: 1769.343s, loss: 0.456, train accuracy: 0.844\n",
      "epoch: 16, time: 1774.567s, loss: 0.416, train accuracy: 0.867\n",
      "epoch: 16, time: 1779.784s, loss: 0.376, train accuracy: 0.891\n",
      "epoch: 16, time: 1785.020s, loss: 0.326, train accuracy: 0.867\n",
      "epoch: 16, time: 1790.233s, loss: 0.368, train accuracy: 0.852\n",
      "epoch: 16, time: 1795.451s, loss: 0.426, train accuracy: 0.852\n",
      "epoch: 16, time: 1800.680s, loss: 0.377, train accuracy: 0.867\n",
      "epoch: 16, time: 1805.905s, loss: 0.470, train accuracy: 0.844\n",
      "epoch: 16, time: 1811.126s, loss: 0.389, train accuracy: 0.852\n",
      "epoch: 16, time: 1816.357s, loss: 0.348, train accuracy: 0.867\n",
      "epoch: 16, time: 1821.574s, loss: 0.431, train accuracy: 0.859\n",
      "epoch: 16, time: 1826.787s, loss: 0.300, train accuracy: 0.883\n",
      "epoch: 16, time: 1832.004s, loss: 0.536, train accuracy: 0.812\n",
      "epoch: 16, time: 1837.219s, loss: 0.571, train accuracy: 0.805\n",
      "epoch: 16, time: 1842.502s, loss: 0.494, train accuracy: 0.812\n",
      "epoch: 16, time: 1847.736s, loss: 0.347, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.825\n",
      "epoch: 17, time: 1857.343s, loss: 0.230, train accuracy: 0.906\n",
      "epoch: 17, time: 1862.561s, loss: 0.331, train accuracy: 0.883\n",
      "epoch: 17, time: 1867.794s, loss: 0.307, train accuracy: 0.891\n",
      "epoch: 17, time: 1873.022s, loss: 0.282, train accuracy: 0.906\n",
      "epoch: 17, time: 1878.247s, loss: 0.422, train accuracy: 0.836\n",
      "epoch: 17, time: 1883.480s, loss: 0.328, train accuracy: 0.875\n",
      "epoch: 17, time: 1888.698s, loss: 0.315, train accuracy: 0.914\n",
      "epoch: 17, time: 1893.935s, loss: 0.416, train accuracy: 0.852\n",
      "epoch: 17, time: 1899.153s, loss: 0.499, train accuracy: 0.836\n",
      "epoch: 17, time: 1904.365s, loss: 0.374, train accuracy: 0.891\n",
      "epoch: 17, time: 1909.580s, loss: 0.295, train accuracy: 0.930\n",
      "epoch: 17, time: 1914.795s, loss: 0.366, train accuracy: 0.844\n",
      "epoch: 17, time: 1920.013s, loss: 0.396, train accuracy: 0.852\n",
      "epoch: 17, time: 1925.248s, loss: 0.428, train accuracy: 0.844\n",
      "epoch: 17, time: 1930.465s, loss: 0.477, train accuracy: 0.844\n",
      "epoch: 17, time: 1935.680s, loss: 0.214, train accuracy: 0.922\n",
      "epoch: 17, time: 1940.897s, loss: 0.358, train accuracy: 0.836\n",
      "epoch: 17, time: 1946.131s, loss: 0.404, train accuracy: 0.852\n",
      "epoch: 17, time: 1951.350s, loss: 0.268, train accuracy: 0.906\n",
      "epoch: 17, time: 1956.586s, loss: 0.499, train accuracy: 0.805\n",
      "Accuracy on the test set: 0.807\n",
      "epoch: 18, time: 1966.240s, loss: 0.390, train accuracy: 0.867\n",
      "epoch: 18, time: 1971.475s, loss: 0.187, train accuracy: 0.930\n",
      "epoch: 18, time: 1976.688s, loss: 0.453, train accuracy: 0.836\n",
      "epoch: 18, time: 1981.902s, loss: 0.322, train accuracy: 0.898\n",
      "epoch: 18, time: 1987.116s, loss: 0.400, train accuracy: 0.844\n",
      "epoch: 18, time: 1992.329s, loss: 0.314, train accuracy: 0.875\n",
      "epoch: 18, time: 1997.545s, loss: 0.480, train accuracy: 0.859\n",
      "epoch: 18, time: 2002.781s, loss: 0.485, train accuracy: 0.844\n",
      "epoch: 18, time: 2008.010s, loss: 0.446, train accuracy: 0.852\n",
      "epoch: 18, time: 2013.242s, loss: 0.570, train accuracy: 0.805\n",
      "epoch: 18, time: 2018.481s, loss: 0.296, train accuracy: 0.875\n",
      "epoch: 18, time: 2023.731s, loss: 0.354, train accuracy: 0.891\n",
      "epoch: 18, time: 2028.970s, loss: 0.319, train accuracy: 0.875\n",
      "epoch: 18, time: 2034.206s, loss: 0.394, train accuracy: 0.875\n",
      "epoch: 18, time: 2039.450s, loss: 0.318, train accuracy: 0.891\n",
      "epoch: 18, time: 2044.696s, loss: 0.395, train accuracy: 0.859\n",
      "epoch: 18, time: 2049.923s, loss: 0.237, train accuracy: 0.922\n",
      "epoch: 18, time: 2055.172s, loss: 0.538, train accuracy: 0.797\n",
      "epoch: 18, time: 2060.412s, loss: 0.266, train accuracy: 0.914\n",
      "epoch: 18, time: 2065.634s, loss: 0.443, train accuracy: 0.820\n",
      "Accuracy on the test set: 0.816\n",
      "epoch: 19, time: 2075.242s, loss: 0.336, train accuracy: 0.883\n",
      "epoch: 19, time: 2080.497s, loss: 0.475, train accuracy: 0.852\n",
      "epoch: 19, time: 2085.736s, loss: 0.490, train accuracy: 0.852\n",
      "epoch: 19, time: 2090.967s, loss: 0.530, train accuracy: 0.820\n",
      "epoch: 19, time: 2096.190s, loss: 0.253, train accuracy: 0.914\n",
      "epoch: 19, time: 2101.404s, loss: 0.293, train accuracy: 0.891\n",
      "epoch: 19, time: 2106.618s, loss: 0.354, train accuracy: 0.844\n",
      "epoch: 19, time: 2111.833s, loss: 0.258, train accuracy: 0.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, time: 2117.071s, loss: 0.285, train accuracy: 0.883\n",
      "epoch: 19, time: 2122.291s, loss: 0.297, train accuracy: 0.867\n",
      "epoch: 19, time: 2127.528s, loss: 0.351, train accuracy: 0.883\n",
      "epoch: 19, time: 2132.753s, loss: 0.277, train accuracy: 0.891\n",
      "epoch: 19, time: 2137.982s, loss: 0.373, train accuracy: 0.883\n",
      "epoch: 19, time: 2143.214s, loss: 0.319, train accuracy: 0.883\n",
      "epoch: 19, time: 2148.436s, loss: 0.327, train accuracy: 0.906\n",
      "epoch: 19, time: 2153.667s, loss: 0.330, train accuracy: 0.891\n",
      "epoch: 19, time: 2158.886s, loss: 0.295, train accuracy: 0.898\n",
      "epoch: 19, time: 2164.100s, loss: 0.298, train accuracy: 0.891\n",
      "epoch: 19, time: 2169.319s, loss: 0.261, train accuracy: 0.930\n",
      "epoch: 19, time: 2174.552s, loss: 0.291, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.828\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(0,20):\n",
    "\n",
    "  net.train()  # Put the network in train mode\n",
    "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "    \n",
    "    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute relevant metrics\n",
    "    \n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
    "\n",
    "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "    # Show progress every 20 batches \n",
    "    if not i % 20:\n",
    "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
    "    \n",
    "    correct_total = 0\n",
    "\n",
    "  net.eval()  # Put the network in eval mode\n",
    "  for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "  print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jcJkRe8T7BW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.828\n"
     ]
    }
   ],
   "source": [
    "correct_total = 0\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "  y_pred = net(x_batch)\n",
    "  y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4RSHW_QT6Ls"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmaaXUzTT6Ix"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cbLSRfqT6F3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet_on_cifar10.ipynb",
   "provenance": [
    {
     "file_id": "1AswAne0soFX43THh56ZlZa7VQfgRLIGo",
     "timestamp": 1576010367797
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
