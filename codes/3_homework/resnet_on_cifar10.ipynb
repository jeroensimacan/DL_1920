{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "resnet_on_cifar10.ipynb",
   "provenance": [
    {
     "file_id": "1AswAne0soFX43THh56ZlZa7VQfgRLIGo",
     "timestamp": 1576010367797
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsdKToFor69U",
    "colab_type": "text"
   },
   "source": [
    "# Homework 3, exercise 2 - Residual Neural Network on CIFAR10\n",
    "\n",
    "In this exercise we implement a (slightly modified) ResNet as introduced in [this paper](https://arxiv.org/pdf/1512.03385.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1VdY58D3KMZO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRuR6CcbsW8_",
    "colab_type": "text"
   },
   "source": [
    "For this exercise it is recommended to use the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rhZQhrlxKSTK",
    "colab_type": "code",
    "outputId": "080851ee-4233-4e39-e5ab-ecde4d88530a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576003485265,
     "user_tz": -60,
     "elapsed": 978,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "device"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwJz3i37UXsZ",
    "colab_type": "text"
   },
   "source": [
    "### Load the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e1WVamZiKSXR",
    "colab_type": "code",
    "outputId": "3ad28be0-c0d3-48f8-de13-5bbdc49dd617",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576005182727,
     "user_tz": -60,
     "elapsed": 2310,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "c, w, h = 3, 32, 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfpdVQRbUg5p",
    "colab_type": "text"
   },
   "source": [
    "## Exercise - Implement a Residual Block\n",
    "\n",
    "Residual neural networks mainly consist of components called Residual Blocks. One residual block can be expressed as **y** = *F*(**x**) + **x** where **x** and **y** are the input and output of the block, respectively. So the input **x** is added to the result of *F*(**x**) using a *skip connection*. In this exercise, *F* consists of:\n",
    "* a convolutional layer with `in_channels` input channels, `hidden_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n",
    "* a batch normalisation layer \n",
    "* ReLU activation\n",
    "* a convolutional layer with `hidden_channels` input channels, `out_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n",
    "* a batch normalisation layer\n",
    "\n",
    "After this the `skip_connection` is applied. If the dimensions of *F*(**x**) and **x** don't match an extra linear projection is applied to **x** so the dimensions do match. This has already been implemented for you. You only need to call it at the right place. \n",
    "Finally, a ReLU activation is applied on the output **y**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HK1qpjYwUFqh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "    super().__init__()\n",
    "\n",
    "    # Complete the code here!\n",
    "    self.layer = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=hidden_channels, kernel_size=(3,3), stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(hidden_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=hidden_channels, out_channels=out_channels, kernel_size=(3,3), stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "    if in_channels != out_channels:  # F(x) and x dimensions do not match! Define a projection for input x\n",
    "      self.skip_connection = nn.Sequential(\n",
    "          nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "          nn.BatchNorm2d(out_channels)\n",
    "      )\n",
    "    else:\n",
    "      self.skip_connection = lambda x: x  # The dimensions already match! No need to do a projection on x\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.skip_connection(x) + self.layer(x)\n"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1Y87D77cYX8",
    "colab_type": "text"
   },
   "source": [
    "## Exercise - Implement a Residual Neural Network\n",
    "Now you can use the previously defined Residual Block to create your ResNet.\n",
    "\n",
    "The network consists of:\n",
    "* a convolutional layer with `in_channels` input channels, 64 output channels, a stride of 1, padding of 1 and no bias parameter,\n",
    "* a batch normalisation layer\n",
    "* ReLU activation\n",
    "* a max pooling layer with kernel size (3, 3), a stride of 2 and padding of 1,\n",
    "* eight residual blocks, with (64, 64, 128, 128, 256, 256, 512, 512) channels, respectively (see code below) \n",
    "* an average pooling layer over all feature maps (already present)\n",
    "* a dense layer to form the output distribution (already present)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0qVgN9lPKSeC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, out_size):\n",
    "    super().__init__()\n",
    "\n",
    "    # Complete the code here!\n",
    "    self.layer = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=(7,7), stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(3,3), stride=2, padding=1)\n",
    "\n",
    "    self.res_blocks = nn.ModuleList(\n",
    "        [\n",
    "         ResidualBlock(64, 64, 64),\n",
    "         ResidualBlock(64, 64, 64),\n",
    "         \n",
    "         ResidualBlock(64, 128, 128),\n",
    "         ResidualBlock(128, 128, 128),\n",
    "         \n",
    "         ResidualBlock(128, 256, 256),\n",
    "         ResidualBlock(256, 256, 256),\n",
    "\n",
    "         ResidualBlock(256, 512, 512),\n",
    "         ResidualBlock(512, 512, 512),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.dense_layer = nn.Linear(512, out_size)\n",
    "    \n",
    "    for module in self.modules():\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "          nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "  def forward(self, x):  \n",
    "\n",
    "    # Complete the code here!\n",
    "    # Add everything that needs to be done before the average pooling\n",
    "    x = self.conv(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    for res_block in self.res_blocks:\n",
    "        x = res_block(x)\n",
    "\n",
    "    x = F.avg_pool2d(x, x.shape[2:])\n",
    "    \n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.dense_layer(x)\n",
    "\n",
    "    return x\n",
    "\n"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ9ny4USgNAu",
    "colab_type": "text"
   },
   "source": [
    "### Initialize the network, Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FIofWmkrT6Oh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = ResNet(c, len(classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojw0pS0dgZHX",
    "colab_type": "text"
   },
   "source": [
    "## Exercise - Train/evaluate the network\n",
    "Train the network you built using the code below. Add the following answers in your report:\n",
    "* What test accuracy were you able to get?\n",
    "* How many layers does your network have? (counting only convolutional and dense layers)\n",
    "* Why do the skip connections help for training deep neural networks?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IcG_bfjoT7Dx",
    "colab_type": "code",
    "outputId": "a5280aa9-5f1c-4867-b0e8-8444b5795ee5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(0,200):\n",
    "\n",
    "  net.train()  # Put the network in train mode\n",
    "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "    \n",
    "    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute relevant metrics\n",
    "    \n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
    "\n",
    "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "    # Show progress every 20 batches \n",
    "    if not i % 20:\n",
    "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
    "    \n",
    "    correct_total = 0\n",
    "\n",
    "  net.eval()  # Put the network in eval mode\n",
    "  for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "  print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, time: 1.124s, loss: 2.326, train accuracy: 0.094\n",
      "epoch: 0, time: 5.195s, loss: 1.898, train accuracy: 0.438\n",
      "epoch: 0, time: 9.260s, loss: 1.824, train accuracy: 0.344\n",
      "epoch: 0, time: 13.320s, loss: 1.595, train accuracy: 0.375\n",
      "epoch: 0, time: 17.378s, loss: 1.809, train accuracy: 0.312\n",
      "epoch: 0, time: 21.437s, loss: 1.958, train accuracy: 0.219\n",
      "epoch: 0, time: 25.496s, loss: 1.791, train accuracy: 0.344\n",
      "epoch: 0, time: 29.556s, loss: 2.221, train accuracy: 0.344\n",
      "epoch: 0, time: 33.617s, loss: 1.748, train accuracy: 0.281\n",
      "epoch: 0, time: 37.681s, loss: 2.258, train accuracy: 0.250\n",
      "epoch: 0, time: 41.743s, loss: 1.869, train accuracy: 0.344\n",
      "epoch: 0, time: 45.803s, loss: 1.633, train accuracy: 0.344\n",
      "epoch: 0, time: 49.867s, loss: 1.616, train accuracy: 0.281\n",
      "epoch: 0, time: 53.929s, loss: 2.022, train accuracy: 0.406\n",
      "epoch: 0, time: 57.991s, loss: 1.426, train accuracy: 0.562\n",
      "epoch: 0, time: 62.052s, loss: 2.068, train accuracy: 0.188\n",
      "epoch: 0, time: 66.113s, loss: 1.837, train accuracy: 0.469\n",
      "epoch: 0, time: 70.175s, loss: 1.845, train accuracy: 0.406\n",
      "epoch: 0, time: 74.233s, loss: 1.658, train accuracy: 0.438\n",
      "epoch: 0, time: 78.296s, loss: 1.549, train accuracy: 0.438\n",
      "epoch: 0, time: 82.356s, loss: 1.753, train accuracy: 0.281\n",
      "epoch: 0, time: 86.417s, loss: 1.302, train accuracy: 0.531\n",
      "epoch: 0, time: 90.484s, loss: 1.775, train accuracy: 0.312\n",
      "epoch: 0, time: 94.547s, loss: 1.633, train accuracy: 0.406\n",
      "epoch: 0, time: 98.615s, loss: 1.896, train accuracy: 0.281\n",
      "epoch: 0, time: 102.687s, loss: 1.778, train accuracy: 0.312\n",
      "epoch: 0, time: 106.752s, loss: 1.391, train accuracy: 0.406\n",
      "epoch: 0, time: 110.820s, loss: 1.348, train accuracy: 0.531\n",
      "epoch: 0, time: 114.883s, loss: 1.656, train accuracy: 0.344\n",
      "epoch: 0, time: 118.947s, loss: 1.479, train accuracy: 0.438\n",
      "epoch: 0, time: 123.011s, loss: 1.277, train accuracy: 0.531\n",
      "epoch: 0, time: 127.079s, loss: 1.676, train accuracy: 0.438\n",
      "epoch: 0, time: 131.143s, loss: 1.262, train accuracy: 0.531\n",
      "epoch: 0, time: 135.207s, loss: 1.665, train accuracy: 0.344\n",
      "epoch: 0, time: 139.271s, loss: 1.410, train accuracy: 0.594\n",
      "epoch: 0, time: 143.337s, loss: 1.346, train accuracy: 0.531\n",
      "epoch: 0, time: 147.407s, loss: 1.440, train accuracy: 0.438\n",
      "epoch: 0, time: 151.471s, loss: 1.649, train accuracy: 0.344\n",
      "epoch: 0, time: 155.537s, loss: 1.480, train accuracy: 0.531\n",
      "epoch: 0, time: 159.603s, loss: 1.448, train accuracy: 0.469\n",
      "epoch: 0, time: 163.666s, loss: 1.438, train accuracy: 0.406\n",
      "epoch: 0, time: 167.734s, loss: 1.692, train accuracy: 0.406\n",
      "epoch: 0, time: 171.803s, loss: 1.530, train accuracy: 0.438\n",
      "epoch: 0, time: 175.871s, loss: 1.283, train accuracy: 0.594\n",
      "epoch: 0, time: 179.938s, loss: 1.638, train accuracy: 0.344\n",
      "epoch: 0, time: 184.005s, loss: 1.475, train accuracy: 0.406\n",
      "epoch: 0, time: 188.074s, loss: 1.334, train accuracy: 0.469\n",
      "epoch: 0, time: 192.141s, loss: 1.574, train accuracy: 0.469\n",
      "epoch: 0, time: 196.208s, loss: 1.561, train accuracy: 0.500\n",
      "epoch: 0, time: 200.272s, loss: 1.429, train accuracy: 0.469\n",
      "epoch: 0, time: 204.341s, loss: 1.211, train accuracy: 0.562\n",
      "epoch: 0, time: 208.412s, loss: 1.458, train accuracy: 0.500\n",
      "epoch: 0, time: 212.483s, loss: 1.407, train accuracy: 0.469\n",
      "epoch: 0, time: 216.550s, loss: 1.535, train accuracy: 0.469\n",
      "epoch: 0, time: 220.617s, loss: 1.128, train accuracy: 0.562\n",
      "epoch: 0, time: 224.686s, loss: 1.581, train accuracy: 0.500\n",
      "epoch: 0, time: 228.752s, loss: 1.410, train accuracy: 0.469\n",
      "epoch: 0, time: 232.820s, loss: 1.544, train accuracy: 0.406\n",
      "epoch: 0, time: 237.037s, loss: 0.949, train accuracy: 0.688\n",
      "epoch: 0, time: 241.288s, loss: 1.295, train accuracy: 0.406\n",
      "epoch: 0, time: 245.385s, loss: 1.092, train accuracy: 0.594\n",
      "epoch: 0, time: 249.468s, loss: 1.481, train accuracy: 0.469\n",
      "epoch: 0, time: 253.554s, loss: 1.239, train accuracy: 0.594\n",
      "epoch: 0, time: 257.816s, loss: 1.461, train accuracy: 0.531\n",
      "epoch: 0, time: 262.015s, loss: 1.343, train accuracy: 0.438\n",
      "epoch: 0, time: 266.133s, loss: 1.308, train accuracy: 0.562\n",
      "epoch: 0, time: 270.260s, loss: 1.077, train accuracy: 0.625\n",
      "epoch: 0, time: 274.380s, loss: 1.207, train accuracy: 0.531\n",
      "epoch: 0, time: 278.502s, loss: 1.599, train accuracy: 0.469\n",
      "epoch: 0, time: 282.634s, loss: 1.375, train accuracy: 0.469\n",
      "epoch: 0, time: 286.966s, loss: 1.478, train accuracy: 0.469\n",
      "epoch: 0, time: 291.283s, loss: 1.149, train accuracy: 0.656\n",
      "epoch: 0, time: 295.417s, loss: 1.424, train accuracy: 0.625\n",
      "epoch: 0, time: 299.710s, loss: 1.045, train accuracy: 0.625\n",
      "epoch: 0, time: 304.062s, loss: 1.447, train accuracy: 0.500\n",
      "epoch: 0, time: 308.419s, loss: 1.380, train accuracy: 0.531\n",
      "epoch: 0, time: 312.770s, loss: 1.280, train accuracy: 0.562\n",
      "epoch: 0, time: 317.115s, loss: 1.051, train accuracy: 0.531\n",
      "epoch: 0, time: 321.262s, loss: 1.100, train accuracy: 0.562\n",
      "Accuracy on the test set: 0.483\n",
      "epoch: 1, time: 343.153s, loss: 1.321, train accuracy: 0.562\n",
      "epoch: 1, time: 347.368s, loss: 1.173, train accuracy: 0.531\n",
      "epoch: 1, time: 351.589s, loss: 1.679, train accuracy: 0.375\n",
      "epoch: 1, time: 355.801s, loss: 1.353, train accuracy: 0.500\n",
      "epoch: 1, time: 360.013s, loss: 1.385, train accuracy: 0.562\n",
      "epoch: 1, time: 364.236s, loss: 1.516, train accuracy: 0.531\n",
      "epoch: 1, time: 368.459s, loss: 1.359, train accuracy: 0.375\n",
      "epoch: 1, time: 372.675s, loss: 1.025, train accuracy: 0.625\n",
      "epoch: 1, time: 376.890s, loss: 1.208, train accuracy: 0.500\n",
      "epoch: 1, time: 381.106s, loss: 1.110, train accuracy: 0.594\n",
      "epoch: 1, time: 385.323s, loss: 1.225, train accuracy: 0.531\n",
      "epoch: 1, time: 389.541s, loss: 1.151, train accuracy: 0.562\n",
      "epoch: 1, time: 393.761s, loss: 1.332, train accuracy: 0.375\n",
      "epoch: 1, time: 397.975s, loss: 1.090, train accuracy: 0.656\n",
      "epoch: 1, time: 402.197s, loss: 1.199, train accuracy: 0.562\n",
      "epoch: 1, time: 406.411s, loss: 1.291, train accuracy: 0.531\n",
      "epoch: 1, time: 410.796s, loss: 1.340, train accuracy: 0.625\n",
      "epoch: 1, time: 415.144s, loss: 1.185, train accuracy: 0.594\n",
      "epoch: 1, time: 419.421s, loss: 1.509, train accuracy: 0.594\n",
      "epoch: 1, time: 423.701s, loss: 1.375, train accuracy: 0.500\n",
      "epoch: 1, time: 427.976s, loss: 1.479, train accuracy: 0.531\n",
      "epoch: 1, time: 432.254s, loss: 1.184, train accuracy: 0.531\n",
      "epoch: 1, time: 436.535s, loss: 1.140, train accuracy: 0.500\n",
      "epoch: 1, time: 440.817s, loss: 1.075, train accuracy: 0.719\n",
      "epoch: 1, time: 445.096s, loss: 1.369, train accuracy: 0.469\n",
      "epoch: 1, time: 449.380s, loss: 1.374, train accuracy: 0.500\n",
      "epoch: 1, time: 453.675s, loss: 1.744, train accuracy: 0.375\n",
      "epoch: 1, time: 457.957s, loss: 1.360, train accuracy: 0.469\n",
      "epoch: 1, time: 462.238s, loss: 1.676, train accuracy: 0.438\n",
      "epoch: 1, time: 466.522s, loss: 1.239, train accuracy: 0.625\n",
      "epoch: 1, time: 470.808s, loss: 1.859, train accuracy: 0.312\n",
      "epoch: 1, time: 475.113s, loss: 1.472, train accuracy: 0.531\n",
      "epoch: 1, time: 479.328s, loss: 1.439, train accuracy: 0.531\n",
      "epoch: 1, time: 483.459s, loss: 1.107, train accuracy: 0.625\n",
      "epoch: 1, time: 487.590s, loss: 1.561, train accuracy: 0.438\n",
      "epoch: 1, time: 491.728s, loss: 1.553, train accuracy: 0.469\n",
      "epoch: 1, time: 495.852s, loss: 1.173, train accuracy: 0.625\n",
      "epoch: 1, time: 499.942s, loss: 1.079, train accuracy: 0.625\n",
      "epoch: 1, time: 504.026s, loss: 1.566, train accuracy: 0.469\n",
      "epoch: 1, time: 508.110s, loss: 1.182, train accuracy: 0.500\n",
      "epoch: 1, time: 512.194s, loss: 1.185, train accuracy: 0.625\n",
      "epoch: 1, time: 516.288s, loss: 1.075, train accuracy: 0.688\n",
      "epoch: 1, time: 520.382s, loss: 0.876, train accuracy: 0.688\n",
      "epoch: 1, time: 524.498s, loss: 1.143, train accuracy: 0.562\n",
      "epoch: 1, time: 528.634s, loss: 1.018, train accuracy: 0.656\n",
      "epoch: 1, time: 532.793s, loss: 1.535, train accuracy: 0.500\n",
      "epoch: 1, time: 536.907s, loss: 1.089, train accuracy: 0.594\n",
      "epoch: 1, time: 541.029s, loss: 1.258, train accuracy: 0.531\n",
      "epoch: 1, time: 545.184s, loss: 1.060, train accuracy: 0.562\n",
      "epoch: 1, time: 549.303s, loss: 1.271, train accuracy: 0.469\n",
      "epoch: 1, time: 553.537s, loss: 1.081, train accuracy: 0.531\n",
      "epoch: 1, time: 557.673s, loss: 1.043, train accuracy: 0.625\n",
      "epoch: 1, time: 561.788s, loss: 1.015, train accuracy: 0.719\n",
      "epoch: 1, time: 565.886s, loss: 0.953, train accuracy: 0.750\n",
      "epoch: 1, time: 569.979s, loss: 1.078, train accuracy: 0.594\n",
      "epoch: 1, time: 574.073s, loss: 1.048, train accuracy: 0.656\n",
      "epoch: 1, time: 578.165s, loss: 1.016, train accuracy: 0.688\n",
      "epoch: 1, time: 582.264s, loss: 1.110, train accuracy: 0.656\n",
      "epoch: 1, time: 586.355s, loss: 1.356, train accuracy: 0.500\n",
      "epoch: 1, time: 590.447s, loss: 0.827, train accuracy: 0.688\n",
      "epoch: 1, time: 594.542s, loss: 1.156, train accuracy: 0.562\n",
      "epoch: 1, time: 598.632s, loss: 1.099, train accuracy: 0.562\n",
      "epoch: 1, time: 602.726s, loss: 1.310, train accuracy: 0.594\n",
      "epoch: 1, time: 606.818s, loss: 1.268, train accuracy: 0.469\n",
      "epoch: 1, time: 610.908s, loss: 1.216, train accuracy: 0.531\n",
      "epoch: 1, time: 615.000s, loss: 1.310, train accuracy: 0.500\n",
      "epoch: 1, time: 619.089s, loss: 0.956, train accuracy: 0.688\n",
      "epoch: 1, time: 623.180s, loss: 0.901, train accuracy: 0.562\n",
      "epoch: 1, time: 627.268s, loss: 1.133, train accuracy: 0.688\n",
      "epoch: 1, time: 631.357s, loss: 0.970, train accuracy: 0.625\n",
      "epoch: 1, time: 635.453s, loss: 1.197, train accuracy: 0.531\n",
      "epoch: 1, time: 639.540s, loss: 1.085, train accuracy: 0.469\n",
      "epoch: 1, time: 643.628s, loss: 1.138, train accuracy: 0.625\n",
      "epoch: 1, time: 647.720s, loss: 1.691, train accuracy: 0.438\n",
      "epoch: 1, time: 651.809s, loss: 1.321, train accuracy: 0.469\n",
      "epoch: 1, time: 655.898s, loss: 1.077, train accuracy: 0.500\n",
      "epoch: 1, time: 659.987s, loss: 1.290, train accuracy: 0.562\n",
      "epoch: 1, time: 664.078s, loss: 0.992, train accuracy: 0.625\n",
      "epoch: 1, time: 668.173s, loss: 1.190, train accuracy: 0.594\n",
      "Accuracy on the test set: 0.580\n",
      "epoch: 2, time: 689.660s, loss: 1.000, train accuracy: 0.625\n",
      "epoch: 2, time: 693.755s, loss: 1.229, train accuracy: 0.594\n",
      "epoch: 2, time: 697.846s, loss: 1.230, train accuracy: 0.531\n",
      "epoch: 2, time: 701.938s, loss: 0.924, train accuracy: 0.719\n",
      "epoch: 2, time: 706.026s, loss: 0.757, train accuracy: 0.719\n",
      "epoch: 2, time: 710.115s, loss: 1.020, train accuracy: 0.719\n",
      "epoch: 2, time: 714.206s, loss: 0.884, train accuracy: 0.625\n",
      "epoch: 2, time: 718.294s, loss: 1.262, train accuracy: 0.531\n",
      "epoch: 2, time: 722.380s, loss: 1.972, train accuracy: 0.344\n",
      "epoch: 2, time: 726.471s, loss: 1.331, train accuracy: 0.625\n",
      "epoch: 2, time: 730.560s, loss: 1.264, train accuracy: 0.562\n",
      "epoch: 2, time: 734.650s, loss: 1.514, train accuracy: 0.500\n",
      "epoch: 2, time: 738.757s, loss: 1.294, train accuracy: 0.562\n",
      "epoch: 2, time: 742.845s, loss: 0.714, train accuracy: 0.812\n",
      "epoch: 2, time: 746.933s, loss: 1.181, train accuracy: 0.625\n",
      "epoch: 2, time: 751.023s, loss: 0.639, train accuracy: 0.781\n",
      "epoch: 2, time: 755.111s, loss: 0.904, train accuracy: 0.594\n",
      "epoch: 2, time: 759.198s, loss: 1.086, train accuracy: 0.625\n",
      "epoch: 2, time: 763.291s, loss: 0.925, train accuracy: 0.750\n",
      "epoch: 2, time: 767.380s, loss: 1.243, train accuracy: 0.719\n",
      "epoch: 2, time: 771.468s, loss: 1.039, train accuracy: 0.625\n",
      "epoch: 2, time: 775.569s, loss: 0.966, train accuracy: 0.625\n",
      "epoch: 2, time: 779.670s, loss: 0.874, train accuracy: 0.750\n",
      "epoch: 2, time: 783.770s, loss: 0.815, train accuracy: 0.688\n",
      "epoch: 2, time: 787.885s, loss: 1.245, train accuracy: 0.625\n",
      "epoch: 2, time: 791.984s, loss: 1.139, train accuracy: 0.531\n",
      "epoch: 2, time: 796.094s, loss: 1.029, train accuracy: 0.625\n",
      "epoch: 2, time: 800.249s, loss: 1.071, train accuracy: 0.656\n",
      "epoch: 2, time: 804.406s, loss: 1.064, train accuracy: 0.594\n",
      "epoch: 2, time: 808.535s, loss: 1.729, train accuracy: 0.406\n",
      "epoch: 2, time: 812.740s, loss: 1.483, train accuracy: 0.344\n",
      "epoch: 2, time: 816.918s, loss: 1.166, train accuracy: 0.625\n",
      "epoch: 2, time: 821.021s, loss: 1.680, train accuracy: 0.375\n",
      "epoch: 2, time: 825.119s, loss: 1.306, train accuracy: 0.531\n",
      "epoch: 2, time: 829.264s, loss: 1.498, train accuracy: 0.594\n",
      "epoch: 2, time: 833.376s, loss: 0.957, train accuracy: 0.656\n",
      "epoch: 2, time: 837.481s, loss: 1.136, train accuracy: 0.625\n",
      "epoch: 2, time: 841.572s, loss: 0.847, train accuracy: 0.688\n",
      "epoch: 2, time: 845.662s, loss: 1.047, train accuracy: 0.719\n",
      "epoch: 2, time: 849.751s, loss: 1.081, train accuracy: 0.625\n",
      "epoch: 2, time: 853.841s, loss: 1.161, train accuracy: 0.656\n",
      "epoch: 2, time: 857.930s, loss: 0.814, train accuracy: 0.719\n",
      "epoch: 2, time: 862.019s, loss: 1.383, train accuracy: 0.469\n",
      "epoch: 2, time: 866.105s, loss: 1.230, train accuracy: 0.500\n",
      "epoch: 2, time: 870.195s, loss: 0.854, train accuracy: 0.688\n",
      "epoch: 2, time: 874.285s, loss: 1.365, train accuracy: 0.438\n",
      "epoch: 2, time: 878.383s, loss: 1.498, train accuracy: 0.531\n",
      "epoch: 2, time: 882.485s, loss: 0.880, train accuracy: 0.750\n",
      "epoch: 2, time: 886.584s, loss: 1.130, train accuracy: 0.656\n",
      "epoch: 2, time: 890.682s, loss: 1.219, train accuracy: 0.500\n",
      "epoch: 2, time: 894.776s, loss: 0.932, train accuracy: 0.656\n",
      "epoch: 2, time: 898.862s, loss: 1.076, train accuracy: 0.594\n",
      "epoch: 2, time: 902.949s, loss: 0.711, train accuracy: 0.719\n",
      "epoch: 2, time: 907.042s, loss: 1.361, train accuracy: 0.500\n",
      "epoch: 2, time: 911.129s, loss: 0.962, train accuracy: 0.719\n",
      "epoch: 2, time: 915.220s, loss: 0.621, train accuracy: 0.844\n",
      "epoch: 2, time: 919.307s, loss: 0.599, train accuracy: 0.781\n",
      "epoch: 2, time: 923.397s, loss: 0.845, train accuracy: 0.656\n",
      "epoch: 2, time: 927.482s, loss: 0.891, train accuracy: 0.688\n",
      "epoch: 2, time: 931.575s, loss: 1.175, train accuracy: 0.562\n",
      "epoch: 2, time: 935.668s, loss: 1.142, train accuracy: 0.594\n",
      "epoch: 2, time: 939.758s, loss: 0.944, train accuracy: 0.656\n",
      "epoch: 2, time: 943.848s, loss: 0.915, train accuracy: 0.688\n",
      "epoch: 2, time: 947.938s, loss: 0.701, train accuracy: 0.688\n",
      "epoch: 2, time: 952.031s, loss: 0.840, train accuracy: 0.750\n",
      "epoch: 2, time: 956.122s, loss: 1.100, train accuracy: 0.469\n",
      "epoch: 2, time: 960.213s, loss: 0.613, train accuracy: 0.812\n",
      "epoch: 2, time: 964.299s, loss: 0.851, train accuracy: 0.688\n",
      "epoch: 2, time: 968.389s, loss: 1.275, train accuracy: 0.594\n",
      "epoch: 2, time: 972.481s, loss: 1.118, train accuracy: 0.531\n",
      "epoch: 2, time: 976.571s, loss: 0.962, train accuracy: 0.656\n",
      "epoch: 2, time: 980.655s, loss: 1.006, train accuracy: 0.594\n",
      "epoch: 2, time: 984.747s, loss: 1.159, train accuracy: 0.594\n",
      "epoch: 2, time: 988.840s, loss: 1.110, train accuracy: 0.594\n",
      "epoch: 2, time: 992.935s, loss: 1.182, train accuracy: 0.500\n",
      "epoch: 2, time: 997.088s, loss: 0.879, train accuracy: 0.625\n",
      "epoch: 2, time: 1001.222s, loss: 0.793, train accuracy: 0.781\n",
      "epoch: 2, time: 1005.312s, loss: 0.874, train accuracy: 0.750\n",
      "epoch: 2, time: 1009.403s, loss: 0.853, train accuracy: 0.625\n",
      "Accuracy on the test set: 0.633\n",
      "epoch: 3, time: 1031.286s, loss: 1.080, train accuracy: 0.688\n",
      "epoch: 3, time: 1035.449s, loss: 1.304, train accuracy: 0.656\n",
      "epoch: 3, time: 1039.674s, loss: 1.068, train accuracy: 0.500\n",
      "epoch: 3, time: 1043.812s, loss: 1.122, train accuracy: 0.531\n",
      "epoch: 3, time: 1047.923s, loss: 0.854, train accuracy: 0.812\n",
      "epoch: 3, time: 1052.128s, loss: 0.673, train accuracy: 0.688\n",
      "epoch: 3, time: 1056.364s, loss: 0.668, train accuracy: 0.750\n",
      "epoch: 3, time: 1060.528s, loss: 0.954, train accuracy: 0.625\n",
      "epoch: 3, time: 1064.682s, loss: 0.806, train accuracy: 0.688\n",
      "epoch: 3, time: 1068.778s, loss: 0.916, train accuracy: 0.875\n",
      "epoch: 3, time: 1072.862s, loss: 0.727, train accuracy: 0.750\n",
      "epoch: 3, time: 1076.989s, loss: 0.872, train accuracy: 0.594\n",
      "epoch: 3, time: 1081.158s, loss: 0.923, train accuracy: 0.688\n",
      "epoch: 3, time: 1085.410s, loss: 1.103, train accuracy: 0.625\n",
      "epoch: 3, time: 1089.547s, loss: 0.742, train accuracy: 0.812\n",
      "epoch: 3, time: 1093.666s, loss: 1.107, train accuracy: 0.562\n",
      "epoch: 3, time: 1097.793s, loss: 0.788, train accuracy: 0.656\n",
      "epoch: 3, time: 1101.892s, loss: 0.870, train accuracy: 0.688\n",
      "epoch: 3, time: 1106.008s, loss: 1.041, train accuracy: 0.750\n",
      "epoch: 3, time: 1110.123s, loss: 1.237, train accuracy: 0.594\n",
      "epoch: 3, time: 1114.253s, loss: 0.986, train accuracy: 0.594\n",
      "epoch: 3, time: 1118.454s, loss: 0.850, train accuracy: 0.719\n",
      "epoch: 3, time: 1122.564s, loss: 0.874, train accuracy: 0.594\n",
      "epoch: 3, time: 1126.689s, loss: 1.041, train accuracy: 0.656\n",
      "epoch: 3, time: 1130.833s, loss: 0.819, train accuracy: 0.656\n",
      "epoch: 3, time: 1134.928s, loss: 0.575, train accuracy: 0.812\n",
      "epoch: 3, time: 1139.022s, loss: 1.163, train accuracy: 0.500\n",
      "epoch: 3, time: 1143.118s, loss: 0.968, train accuracy: 0.750\n",
      "epoch: 3, time: 1147.215s, loss: 0.619, train accuracy: 0.750\n",
      "epoch: 3, time: 1151.310s, loss: 1.034, train accuracy: 0.500\n",
      "epoch: 3, time: 1155.403s, loss: 1.146, train accuracy: 0.594\n",
      "epoch: 3, time: 1159.505s, loss: 0.794, train accuracy: 0.625\n",
      "epoch: 3, time: 1163.603s, loss: 0.774, train accuracy: 0.719\n",
      "epoch: 3, time: 1167.702s, loss: 0.951, train accuracy: 0.719\n",
      "epoch: 3, time: 1171.800s, loss: 1.211, train accuracy: 0.562\n",
      "epoch: 3, time: 1175.930s, loss: 0.731, train accuracy: 0.750\n",
      "epoch: 3, time: 1180.048s, loss: 0.613, train accuracy: 0.781\n",
      "epoch: 3, time: 1184.159s, loss: 0.886, train accuracy: 0.719\n",
      "epoch: 3, time: 1188.276s, loss: 0.831, train accuracy: 0.750\n",
      "epoch: 3, time: 1192.412s, loss: 1.069, train accuracy: 0.594\n",
      "epoch: 3, time: 1196.515s, loss: 0.854, train accuracy: 0.719\n",
      "epoch: 3, time: 1200.605s, loss: 0.747, train accuracy: 0.688\n",
      "epoch: 3, time: 1204.700s, loss: 0.749, train accuracy: 0.812\n",
      "epoch: 3, time: 1208.809s, loss: 1.035, train accuracy: 0.688\n",
      "epoch: 3, time: 1212.913s, loss: 0.757, train accuracy: 0.719\n",
      "epoch: 3, time: 1217.013s, loss: 0.988, train accuracy: 0.688\n",
      "epoch: 3, time: 1221.124s, loss: 1.061, train accuracy: 0.656\n",
      "epoch: 3, time: 1225.243s, loss: 1.322, train accuracy: 0.531\n",
      "epoch: 3, time: 1229.387s, loss: 0.970, train accuracy: 0.625\n",
      "epoch: 3, time: 1233.491s, loss: 0.995, train accuracy: 0.656\n",
      "epoch: 3, time: 1237.586s, loss: 1.042, train accuracy: 0.719\n",
      "epoch: 3, time: 1241.688s, loss: 0.729, train accuracy: 0.750\n",
      "epoch: 3, time: 1245.851s, loss: 1.018, train accuracy: 0.625\n",
      "epoch: 3, time: 1250.026s, loss: 1.087, train accuracy: 0.500\n",
      "epoch: 3, time: 1254.153s, loss: 0.669, train accuracy: 0.656\n",
      "epoch: 3, time: 1258.249s, loss: 0.862, train accuracy: 0.750\n",
      "epoch: 3, time: 1262.340s, loss: 0.588, train accuracy: 0.781\n",
      "epoch: 3, time: 1266.470s, loss: 1.165, train accuracy: 0.656\n",
      "epoch: 3, time: 1270.575s, loss: 1.348, train accuracy: 0.531\n",
      "epoch: 3, time: 1274.687s, loss: 0.957, train accuracy: 0.594\n",
      "epoch: 3, time: 1278.807s, loss: 0.829, train accuracy: 0.719\n",
      "epoch: 3, time: 1282.937s, loss: 1.044, train accuracy: 0.656\n",
      "epoch: 3, time: 1287.056s, loss: 0.856, train accuracy: 0.656\n",
      "epoch: 3, time: 1291.153s, loss: 0.807, train accuracy: 0.750\n",
      "epoch: 3, time: 1295.244s, loss: 1.005, train accuracy: 0.625\n",
      "epoch: 3, time: 1299.328s, loss: 1.307, train accuracy: 0.500\n",
      "epoch: 3, time: 1303.426s, loss: 0.943, train accuracy: 0.656\n",
      "epoch: 3, time: 1307.514s, loss: 0.956, train accuracy: 0.750\n",
      "epoch: 3, time: 1311.611s, loss: 1.178, train accuracy: 0.562\n",
      "epoch: 3, time: 1315.704s, loss: 1.146, train accuracy: 0.688\n",
      "epoch: 3, time: 1319.813s, loss: 0.937, train accuracy: 0.688\n",
      "epoch: 3, time: 1324.011s, loss: 1.149, train accuracy: 0.625\n",
      "epoch: 3, time: 1328.129s, loss: 1.015, train accuracy: 0.719\n",
      "epoch: 3, time: 1332.229s, loss: 0.935, train accuracy: 0.812\n",
      "epoch: 3, time: 1336.353s, loss: 0.828, train accuracy: 0.656\n",
      "epoch: 3, time: 1340.448s, loss: 0.841, train accuracy: 0.688\n",
      "epoch: 3, time: 1344.549s, loss: 1.120, train accuracy: 0.656\n",
      "epoch: 3, time: 1348.637s, loss: 0.878, train accuracy: 0.656\n",
      "epoch: 3, time: 1352.739s, loss: 0.642, train accuracy: 0.750\n",
      "Accuracy on the test set: 0.668\n",
      "epoch: 4, time: 1374.247s, loss: 1.065, train accuracy: 0.562\n",
      "epoch: 4, time: 1378.356s, loss: 0.504, train accuracy: 0.781\n",
      "epoch: 4, time: 1382.453s, loss: 0.790, train accuracy: 0.750\n",
      "epoch: 4, time: 1386.543s, loss: 1.171, train accuracy: 0.469\n",
      "epoch: 4, time: 1390.637s, loss: 0.778, train accuracy: 0.688\n",
      "epoch: 4, time: 1394.726s, loss: 0.654, train accuracy: 0.781\n",
      "epoch: 4, time: 1398.811s, loss: 0.943, train accuracy: 0.688\n",
      "epoch: 4, time: 1402.896s, loss: 0.597, train accuracy: 0.844\n",
      "epoch: 4, time: 1406.981s, loss: 0.818, train accuracy: 0.656\n",
      "epoch: 4, time: 1411.070s, loss: 0.749, train accuracy: 0.719\n",
      "epoch: 4, time: 1415.158s, loss: 1.036, train accuracy: 0.719\n",
      "epoch: 4, time: 1419.263s, loss: 0.741, train accuracy: 0.750\n",
      "epoch: 4, time: 1423.439s, loss: 1.077, train accuracy: 0.531\n",
      "epoch: 4, time: 1427.601s, loss: 1.176, train accuracy: 0.562\n",
      "epoch: 4, time: 1431.935s, loss: 0.836, train accuracy: 0.719\n",
      "epoch: 4, time: 1436.090s, loss: 1.033, train accuracy: 0.562\n",
      "epoch: 4, time: 1440.229s, loss: 0.830, train accuracy: 0.688\n",
      "epoch: 4, time: 1444.340s, loss: 1.039, train accuracy: 0.625\n",
      "epoch: 4, time: 1448.443s, loss: 0.998, train accuracy: 0.656\n",
      "epoch: 4, time: 1452.543s, loss: 0.952, train accuracy: 0.656\n",
      "epoch: 4, time: 1456.642s, loss: 0.605, train accuracy: 0.750\n",
      "epoch: 4, time: 1460.743s, loss: 0.854, train accuracy: 0.812\n",
      "epoch: 4, time: 1464.839s, loss: 0.641, train accuracy: 0.719\n",
      "epoch: 4, time: 1468.940s, loss: 0.698, train accuracy: 0.719\n",
      "epoch: 4, time: 1473.047s, loss: 1.033, train accuracy: 0.562\n",
      "epoch: 4, time: 1477.303s, loss: 0.767, train accuracy: 0.750\n",
      "epoch: 4, time: 1481.510s, loss: 0.688, train accuracy: 0.750\n",
      "epoch: 4, time: 1485.720s, loss: 0.959, train accuracy: 0.594\n",
      "epoch: 4, time: 1489.815s, loss: 0.867, train accuracy: 0.625\n",
      "epoch: 4, time: 1493.925s, loss: 0.616, train accuracy: 0.812\n",
      "epoch: 4, time: 1498.023s, loss: 0.701, train accuracy: 0.750\n",
      "epoch: 4, time: 1502.206s, loss: 0.781, train accuracy: 0.719\n",
      "epoch: 4, time: 1506.350s, loss: 1.011, train accuracy: 0.625\n",
      "epoch: 4, time: 1510.444s, loss: 0.718, train accuracy: 0.750\n",
      "epoch: 4, time: 1514.538s, loss: 0.952, train accuracy: 0.625\n",
      "epoch: 4, time: 1518.637s, loss: 0.972, train accuracy: 0.750\n",
      "epoch: 4, time: 1522.736s, loss: 0.589, train accuracy: 0.781\n",
      "epoch: 4, time: 1526.841s, loss: 0.657, train accuracy: 0.750\n",
      "epoch: 4, time: 1530.971s, loss: 1.102, train accuracy: 0.656\n",
      "epoch: 4, time: 1535.172s, loss: 0.859, train accuracy: 0.688\n",
      "epoch: 4, time: 1539.393s, loss: 0.897, train accuracy: 0.688\n",
      "epoch: 4, time: 1543.625s, loss: 1.294, train accuracy: 0.562\n",
      "epoch: 4, time: 1547.814s, loss: 0.644, train accuracy: 0.812\n",
      "epoch: 4, time: 1551.991s, loss: 0.952, train accuracy: 0.688\n",
      "epoch: 4, time: 1556.106s, loss: 0.901, train accuracy: 0.719\n",
      "epoch: 4, time: 1560.223s, loss: 1.048, train accuracy: 0.594\n",
      "epoch: 4, time: 1564.393s, loss: 0.815, train accuracy: 0.719\n",
      "epoch: 4, time: 1568.748s, loss: 0.552, train accuracy: 0.875\n",
      "epoch: 4, time: 1573.090s, loss: 0.586, train accuracy: 0.844\n",
      "epoch: 4, time: 1577.396s, loss: 0.693, train accuracy: 0.812\n",
      "epoch: 4, time: 1581.748s, loss: 0.553, train accuracy: 0.875\n",
      "epoch: 4, time: 1585.971s, loss: 0.814, train accuracy: 0.656\n",
      "epoch: 4, time: 1590.268s, loss: 0.525, train accuracy: 0.750\n",
      "epoch: 4, time: 1594.572s, loss: 0.487, train accuracy: 0.781\n",
      "epoch: 4, time: 1598.855s, loss: 0.545, train accuracy: 0.875\n",
      "epoch: 4, time: 1603.147s, loss: 0.727, train accuracy: 0.781\n",
      "epoch: 4, time: 1607.330s, loss: 0.893, train accuracy: 0.750\n",
      "epoch: 4, time: 1611.495s, loss: 0.497, train accuracy: 0.781\n",
      "epoch: 4, time: 1615.667s, loss: 0.598, train accuracy: 0.781\n",
      "epoch: 4, time: 1619.833s, loss: 0.918, train accuracy: 0.688\n",
      "epoch: 4, time: 1623.957s, loss: 0.774, train accuracy: 0.688\n",
      "epoch: 4, time: 1628.053s, loss: 0.880, train accuracy: 0.656\n",
      "epoch: 4, time: 1632.143s, loss: 0.962, train accuracy: 0.625\n",
      "epoch: 4, time: 1636.238s, loss: 0.552, train accuracy: 0.844\n",
      "epoch: 4, time: 1640.334s, loss: 0.709, train accuracy: 0.719\n",
      "epoch: 4, time: 1644.429s, loss: 0.539, train accuracy: 0.812\n",
      "epoch: 4, time: 1648.521s, loss: 0.946, train accuracy: 0.750\n",
      "epoch: 4, time: 1652.611s, loss: 0.768, train accuracy: 0.750\n",
      "epoch: 4, time: 1656.709s, loss: 0.371, train accuracy: 0.906\n",
      "epoch: 4, time: 1660.800s, loss: 0.790, train accuracy: 0.656\n",
      "epoch: 4, time: 1664.909s, loss: 1.109, train accuracy: 0.719\n",
      "epoch: 4, time: 1669.095s, loss: 0.571, train accuracy: 0.750\n",
      "epoch: 4, time: 1673.277s, loss: 0.646, train accuracy: 0.812\n",
      "epoch: 4, time: 1677.550s, loss: 0.806, train accuracy: 0.719\n",
      "epoch: 4, time: 1681.719s, loss: 0.628, train accuracy: 0.844\n",
      "epoch: 4, time: 1685.870s, loss: 0.951, train accuracy: 0.594\n",
      "epoch: 4, time: 1690.036s, loss: 0.837, train accuracy: 0.719\n",
      "epoch: 4, time: 1694.230s, loss: 1.028, train accuracy: 0.750\n",
      "epoch: 4, time: 1698.372s, loss: 0.759, train accuracy: 0.719\n",
      "Accuracy on the test set: 0.689\n",
      "epoch: 5, time: 1719.978s, loss: 0.643, train accuracy: 0.781\n",
      "epoch: 5, time: 1724.175s, loss: 0.788, train accuracy: 0.750\n",
      "epoch: 5, time: 1728.343s, loss: 0.851, train accuracy: 0.688\n",
      "epoch: 5, time: 1732.486s, loss: 0.635, train accuracy: 0.812\n",
      "epoch: 5, time: 1736.639s, loss: 0.516, train accuracy: 0.812\n",
      "epoch: 5, time: 1740.769s, loss: 0.999, train accuracy: 0.688\n",
      "epoch: 5, time: 1744.924s, loss: 1.098, train accuracy: 0.656\n",
      "epoch: 5, time: 1749.054s, loss: 0.713, train accuracy: 0.719\n",
      "epoch: 5, time: 1753.188s, loss: 0.886, train accuracy: 0.719\n",
      "epoch: 5, time: 1757.318s, loss: 0.550, train accuracy: 0.812\n",
      "epoch: 5, time: 1761.449s, loss: 0.901, train accuracy: 0.656\n",
      "epoch: 5, time: 1765.585s, loss: 0.744, train accuracy: 0.750\n",
      "epoch: 5, time: 1769.725s, loss: 0.752, train accuracy: 0.750\n",
      "epoch: 5, time: 1773.876s, loss: 1.027, train accuracy: 0.688\n",
      "epoch: 5, time: 1778.027s, loss: 0.715, train accuracy: 0.812\n",
      "epoch: 5, time: 1782.199s, loss: 0.621, train accuracy: 0.719\n",
      "epoch: 5, time: 1786.339s, loss: 0.493, train accuracy: 0.781\n",
      "epoch: 5, time: 1790.489s, loss: 0.973, train accuracy: 0.688\n",
      "epoch: 5, time: 1794.625s, loss: 0.706, train accuracy: 0.750\n",
      "epoch: 5, time: 1798.759s, loss: 0.525, train accuracy: 0.781\n",
      "epoch: 5, time: 1802.893s, loss: 0.620, train accuracy: 0.844\n",
      "epoch: 5, time: 1807.021s, loss: 1.078, train accuracy: 0.688\n",
      "epoch: 5, time: 1811.155s, loss: 0.904, train accuracy: 0.719\n",
      "epoch: 5, time: 1815.288s, loss: 0.807, train accuracy: 0.781\n",
      "epoch: 5, time: 1819.420s, loss: 0.910, train accuracy: 0.625\n",
      "epoch: 5, time: 1823.554s, loss: 0.490, train accuracy: 0.875\n",
      "epoch: 5, time: 1827.688s, loss: 0.789, train accuracy: 0.688\n",
      "epoch: 5, time: 1831.843s, loss: 0.614, train accuracy: 0.844\n",
      "epoch: 5, time: 1835.990s, loss: 0.892, train accuracy: 0.719\n",
      "epoch: 5, time: 1840.115s, loss: 0.874, train accuracy: 0.781\n",
      "epoch: 5, time: 1844.249s, loss: 0.673, train accuracy: 0.688\n",
      "epoch: 5, time: 1848.385s, loss: 0.716, train accuracy: 0.688\n",
      "epoch: 5, time: 1852.515s, loss: 0.989, train accuracy: 0.656\n",
      "epoch: 5, time: 1856.651s, loss: 0.594, train accuracy: 0.844\n",
      "epoch: 5, time: 1860.792s, loss: 0.557, train accuracy: 0.750\n",
      "epoch: 5, time: 1864.927s, loss: 0.640, train accuracy: 0.781\n",
      "epoch: 5, time: 1869.057s, loss: 0.857, train accuracy: 0.688\n",
      "epoch: 5, time: 1873.202s, loss: 0.881, train accuracy: 0.656\n",
      "epoch: 5, time: 1877.328s, loss: 0.843, train accuracy: 0.594\n",
      "epoch: 5, time: 1881.455s, loss: 0.528, train accuracy: 0.812\n",
      "epoch: 5, time: 1885.584s, loss: 0.747, train accuracy: 0.688\n",
      "epoch: 5, time: 1889.722s, loss: 0.649, train accuracy: 0.688\n",
      "epoch: 5, time: 1893.867s, loss: 0.701, train accuracy: 0.719\n",
      "epoch: 5, time: 1898.004s, loss: 0.918, train accuracy: 0.656\n",
      "epoch: 5, time: 1902.136s, loss: 0.714, train accuracy: 0.688\n",
      "epoch: 5, time: 1906.280s, loss: 0.680, train accuracy: 0.688\n",
      "epoch: 5, time: 1910.415s, loss: 0.601, train accuracy: 0.812\n",
      "epoch: 5, time: 1914.546s, loss: 0.793, train accuracy: 0.625\n",
      "epoch: 5, time: 1918.676s, loss: 0.860, train accuracy: 0.656\n",
      "epoch: 5, time: 1922.806s, loss: 0.818, train accuracy: 0.781\n",
      "epoch: 5, time: 1926.936s, loss: 0.694, train accuracy: 0.812\n",
      "epoch: 5, time: 1931.079s, loss: 0.683, train accuracy: 0.781\n",
      "epoch: 5, time: 1935.203s, loss: 0.897, train accuracy: 0.719\n",
      "epoch: 5, time: 1939.331s, loss: 1.145, train accuracy: 0.625\n",
      "epoch: 5, time: 1943.456s, loss: 0.624, train accuracy: 0.750\n",
      "epoch: 5, time: 1947.584s, loss: 0.771, train accuracy: 0.844\n",
      "epoch: 5, time: 1951.716s, loss: 0.859, train accuracy: 0.688\n",
      "epoch: 5, time: 1955.865s, loss: 1.034, train accuracy: 0.656\n",
      "epoch: 5, time: 1959.991s, loss: 0.842, train accuracy: 0.688\n",
      "epoch: 5, time: 1964.129s, loss: 1.192, train accuracy: 0.719\n",
      "epoch: 5, time: 1968.265s, loss: 0.732, train accuracy: 0.688\n",
      "epoch: 5, time: 1972.397s, loss: 0.550, train accuracy: 0.844\n",
      "epoch: 5, time: 1976.538s, loss: 0.588, train accuracy: 0.750\n",
      "epoch: 5, time: 1980.667s, loss: 0.781, train accuracy: 0.719\n",
      "epoch: 5, time: 1984.801s, loss: 0.874, train accuracy: 0.719\n",
      "epoch: 5, time: 1988.940s, loss: 0.606, train accuracy: 0.812\n",
      "epoch: 5, time: 1993.068s, loss: 1.068, train accuracy: 0.594\n",
      "epoch: 5, time: 1997.201s, loss: 0.998, train accuracy: 0.656\n",
      "epoch: 5, time: 2001.333s, loss: 0.673, train accuracy: 0.781\n",
      "epoch: 5, time: 2005.468s, loss: 0.736, train accuracy: 0.719\n",
      "epoch: 5, time: 2009.600s, loss: 0.759, train accuracy: 0.750\n",
      "epoch: 5, time: 2013.739s, loss: 0.747, train accuracy: 0.719\n",
      "epoch: 5, time: 2017.880s, loss: 0.912, train accuracy: 0.719\n",
      "epoch: 5, time: 2022.013s, loss: 0.424, train accuracy: 0.875\n",
      "epoch: 5, time: 2026.143s, loss: 0.829, train accuracy: 0.719\n",
      "epoch: 5, time: 2030.296s, loss: 0.721, train accuracy: 0.656\n",
      "epoch: 5, time: 2034.422s, loss: 0.588, train accuracy: 0.781\n",
      "epoch: 5, time: 2038.550s, loss: 0.913, train accuracy: 0.812\n",
      "epoch: 5, time: 2042.677s, loss: 0.815, train accuracy: 0.781\n",
      "Accuracy on the test set: 0.736\n",
      "epoch: 6, time: 2064.157s, loss: 0.909, train accuracy: 0.719\n",
      "epoch: 6, time: 2068.444s, loss: 0.857, train accuracy: 0.688\n",
      "epoch: 6, time: 2072.657s, loss: 0.642, train accuracy: 0.812\n",
      "epoch: 6, time: 2076.823s, loss: 0.923, train accuracy: 0.750\n",
      "epoch: 6, time: 2080.975s, loss: 0.401, train accuracy: 0.906\n",
      "epoch: 6, time: 2085.133s, loss: 0.874, train accuracy: 0.781\n",
      "epoch: 6, time: 2089.284s, loss: 0.712, train accuracy: 0.750\n",
      "epoch: 6, time: 2093.431s, loss: 0.908, train accuracy: 0.625\n",
      "epoch: 6, time: 2097.579s, loss: 0.569, train accuracy: 0.781\n",
      "epoch: 6, time: 2101.724s, loss: 0.596, train accuracy: 0.812\n",
      "epoch: 6, time: 2105.872s, loss: 0.797, train accuracy: 0.594\n",
      "epoch: 6, time: 2110.023s, loss: 1.156, train accuracy: 0.594\n",
      "epoch: 6, time: 2114.169s, loss: 0.652, train accuracy: 0.688\n",
      "epoch: 6, time: 2118.326s, loss: 0.494, train accuracy: 0.844\n",
      "epoch: 6, time: 2122.481s, loss: 0.864, train accuracy: 0.781\n",
      "epoch: 6, time: 2126.634s, loss: 0.501, train accuracy: 0.844\n",
      "epoch: 6, time: 2130.786s, loss: 0.788, train accuracy: 0.750\n",
      "epoch: 6, time: 2134.955s, loss: 0.761, train accuracy: 0.812\n",
      "epoch: 6, time: 2139.102s, loss: 0.491, train accuracy: 0.812\n",
      "epoch: 6, time: 2143.246s, loss: 0.580, train accuracy: 0.844\n",
      "epoch: 6, time: 2147.394s, loss: 0.525, train accuracy: 0.844\n",
      "epoch: 6, time: 2151.541s, loss: 0.757, train accuracy: 0.781\n",
      "epoch: 6, time: 2155.688s, loss: 0.865, train accuracy: 0.719\n",
      "epoch: 6, time: 2159.840s, loss: 0.649, train accuracy: 0.750\n",
      "epoch: 6, time: 2163.989s, loss: 0.888, train accuracy: 0.719\n",
      "epoch: 6, time: 2168.140s, loss: 0.651, train accuracy: 0.844\n",
      "epoch: 6, time: 2172.292s, loss: 0.660, train accuracy: 0.750\n",
      "epoch: 6, time: 2176.439s, loss: 1.227, train accuracy: 0.656\n",
      "epoch: 6, time: 2180.588s, loss: 0.560, train accuracy: 0.812\n",
      "epoch: 6, time: 2184.732s, loss: 0.860, train accuracy: 0.719\n",
      "epoch: 6, time: 2188.884s, loss: 0.767, train accuracy: 0.656\n",
      "epoch: 6, time: 2193.034s, loss: 1.048, train accuracy: 0.688\n",
      "epoch: 6, time: 2197.201s, loss: 0.644, train accuracy: 0.750\n",
      "epoch: 6, time: 2201.357s, loss: 1.118, train accuracy: 0.594\n",
      "epoch: 6, time: 2205.520s, loss: 0.696, train accuracy: 0.781\n",
      "epoch: 6, time: 2209.669s, loss: 0.813, train accuracy: 0.750\n",
      "epoch: 6, time: 2213.821s, loss: 1.074, train accuracy: 0.750\n",
      "epoch: 6, time: 2217.969s, loss: 0.841, train accuracy: 0.656\n",
      "epoch: 6, time: 2222.122s, loss: 0.909, train accuracy: 0.719\n",
      "epoch: 6, time: 2226.272s, loss: 1.064, train accuracy: 0.531\n",
      "epoch: 6, time: 2230.423s, loss: 0.644, train accuracy: 0.781\n",
      "epoch: 6, time: 2234.573s, loss: 0.389, train accuracy: 0.844\n",
      "epoch: 6, time: 2238.726s, loss: 0.388, train accuracy: 0.844\n",
      "epoch: 6, time: 2242.874s, loss: 0.705, train accuracy: 0.750\n",
      "epoch: 6, time: 2247.023s, loss: 0.821, train accuracy: 0.750\n",
      "epoch: 6, time: 2251.177s, loss: 0.730, train accuracy: 0.688\n",
      "epoch: 6, time: 2255.334s, loss: 0.868, train accuracy: 0.656\n",
      "epoch: 6, time: 2259.483s, loss: 0.590, train accuracy: 0.812\n",
      "epoch: 6, time: 2263.633s, loss: 0.511, train accuracy: 0.812\n",
      "epoch: 6, time: 2267.808s, loss: 0.664, train accuracy: 0.688\n",
      "epoch: 6, time: 2271.978s, loss: 0.616, train accuracy: 0.812\n",
      "epoch: 6, time: 2276.170s, loss: 0.711, train accuracy: 0.719\n",
      "epoch: 6, time: 2280.320s, loss: 0.486, train accuracy: 0.875\n",
      "epoch: 6, time: 2284.483s, loss: 0.649, train accuracy: 0.781\n",
      "epoch: 6, time: 2288.630s, loss: 0.664, train accuracy: 0.719\n",
      "epoch: 6, time: 2292.780s, loss: 0.493, train accuracy: 0.844\n",
      "epoch: 6, time: 2296.926s, loss: 0.486, train accuracy: 0.812\n",
      "epoch: 6, time: 2301.074s, loss: 0.500, train accuracy: 0.875\n",
      "epoch: 6, time: 2305.225s, loss: 0.832, train accuracy: 0.625\n",
      "epoch: 6, time: 2309.403s, loss: 0.611, train accuracy: 0.812\n",
      "epoch: 6, time: 2313.576s, loss: 0.539, train accuracy: 0.812\n",
      "epoch: 6, time: 2317.751s, loss: 0.563, train accuracy: 0.781\n",
      "epoch: 6, time: 2321.932s, loss: 0.733, train accuracy: 0.688\n",
      "epoch: 6, time: 2326.091s, loss: 0.784, train accuracy: 0.719\n",
      "epoch: 6, time: 2330.244s, loss: 0.655, train accuracy: 0.781\n",
      "epoch: 6, time: 2334.400s, loss: 0.667, train accuracy: 0.750\n",
      "epoch: 6, time: 2338.556s, loss: 0.546, train accuracy: 0.875\n",
      "epoch: 6, time: 2342.708s, loss: 0.683, train accuracy: 0.750\n",
      "epoch: 6, time: 2346.867s, loss: 0.682, train accuracy: 0.719\n",
      "epoch: 6, time: 2351.034s, loss: 0.780, train accuracy: 0.750\n",
      "epoch: 6, time: 2355.189s, loss: 0.351, train accuracy: 0.844\n",
      "epoch: 6, time: 2359.353s, loss: 0.780, train accuracy: 0.719\n",
      "epoch: 6, time: 2363.511s, loss: 0.622, train accuracy: 0.719\n",
      "epoch: 6, time: 2367.672s, loss: 0.880, train accuracy: 0.656\n",
      "epoch: 6, time: 2371.839s, loss: 0.419, train accuracy: 0.844\n",
      "epoch: 6, time: 2376.064s, loss: 1.272, train accuracy: 0.594\n",
      "epoch: 6, time: 2380.250s, loss: 0.930, train accuracy: 0.625\n",
      "epoch: 6, time: 2384.423s, loss: 0.427, train accuracy: 0.781\n",
      "epoch: 6, time: 2388.621s, loss: 0.629, train accuracy: 0.781\n",
      "Accuracy on the test set: 0.765\n",
      "epoch: 7, time: 2410.373s, loss: 0.824, train accuracy: 0.719\n",
      "epoch: 7, time: 2414.548s, loss: 0.643, train accuracy: 0.781\n",
      "epoch: 7, time: 2418.716s, loss: 0.408, train accuracy: 0.844\n",
      "epoch: 7, time: 2422.866s, loss: 0.672, train accuracy: 0.719\n",
      "epoch: 7, time: 2427.024s, loss: 0.814, train accuracy: 0.750\n",
      "epoch: 7, time: 2431.173s, loss: 0.543, train accuracy: 0.812\n",
      "epoch: 7, time: 2435.347s, loss: 0.279, train accuracy: 0.938\n",
      "epoch: 7, time: 2439.503s, loss: 0.771, train accuracy: 0.750\n",
      "epoch: 7, time: 2443.649s, loss: 0.485, train accuracy: 0.844\n",
      "epoch: 7, time: 2447.801s, loss: 1.018, train accuracy: 0.656\n",
      "epoch: 7, time: 2451.951s, loss: 0.685, train accuracy: 0.688\n",
      "epoch: 7, time: 2456.092s, loss: 0.814, train accuracy: 0.781\n",
      "epoch: 7, time: 2460.250s, loss: 0.873, train accuracy: 0.750\n",
      "epoch: 7, time: 2464.399s, loss: 0.777, train accuracy: 0.750\n",
      "epoch: 7, time: 2468.545s, loss: 0.773, train accuracy: 0.750\n",
      "epoch: 7, time: 2472.713s, loss: 0.662, train accuracy: 0.781\n",
      "epoch: 7, time: 2476.867s, loss: 0.548, train accuracy: 0.844\n",
      "epoch: 7, time: 2481.037s, loss: 0.643, train accuracy: 0.781\n",
      "epoch: 7, time: 2485.216s, loss: 0.877, train accuracy: 0.688\n",
      "epoch: 7, time: 2489.385s, loss: 0.399, train accuracy: 0.875\n",
      "epoch: 7, time: 2493.548s, loss: 0.612, train accuracy: 0.781\n",
      "epoch: 7, time: 2497.709s, loss: 0.626, train accuracy: 0.844\n",
      "epoch: 7, time: 2501.859s, loss: 1.053, train accuracy: 0.625\n",
      "epoch: 7, time: 2506.002s, loss: 0.934, train accuracy: 0.688\n",
      "epoch: 7, time: 2510.157s, loss: 0.748, train accuracy: 0.719\n",
      "epoch: 7, time: 2514.301s, loss: 0.865, train accuracy: 0.656\n",
      "epoch: 7, time: 2518.444s, loss: 0.503, train accuracy: 0.781\n",
      "epoch: 7, time: 2522.599s, loss: 0.886, train accuracy: 0.656\n",
      "epoch: 7, time: 2526.759s, loss: 0.739, train accuracy: 0.750\n",
      "epoch: 7, time: 2530.900s, loss: 0.724, train accuracy: 0.719\n",
      "epoch: 7, time: 2535.059s, loss: 0.997, train accuracy: 0.625\n",
      "epoch: 7, time: 2539.226s, loss: 0.888, train accuracy: 0.719\n",
      "epoch: 7, time: 2543.374s, loss: 0.446, train accuracy: 0.812\n",
      "epoch: 7, time: 2547.524s, loss: 0.894, train accuracy: 0.625\n",
      "epoch: 7, time: 2551.667s, loss: 0.670, train accuracy: 0.781\n",
      "epoch: 7, time: 2555.830s, loss: 0.979, train accuracy: 0.688\n",
      "epoch: 7, time: 2559.978s, loss: 0.734, train accuracy: 0.688\n",
      "epoch: 7, time: 2564.136s, loss: 0.577, train accuracy: 0.812\n",
      "epoch: 7, time: 2568.285s, loss: 0.586, train accuracy: 0.781\n",
      "epoch: 7, time: 2572.429s, loss: 0.939, train accuracy: 0.688\n",
      "epoch: 7, time: 2576.577s, loss: 0.823, train accuracy: 0.781\n",
      "epoch: 7, time: 2580.724s, loss: 1.041, train accuracy: 0.500\n",
      "epoch: 7, time: 2584.867s, loss: 0.560, train accuracy: 0.781\n",
      "epoch: 7, time: 2589.024s, loss: 0.656, train accuracy: 0.812\n",
      "epoch: 7, time: 2593.168s, loss: 0.704, train accuracy: 0.719\n",
      "epoch: 7, time: 2597.310s, loss: 0.393, train accuracy: 0.812\n",
      "epoch: 7, time: 2601.453s, loss: 0.565, train accuracy: 0.844\n",
      "epoch: 7, time: 2605.592s, loss: 0.602, train accuracy: 0.719\n",
      "epoch: 7, time: 2609.735s, loss: 0.891, train accuracy: 0.750\n",
      "epoch: 7, time: 2613.883s, loss: 0.893, train accuracy: 0.719\n",
      "epoch: 7, time: 2618.030s, loss: 0.648, train accuracy: 0.781\n",
      "epoch: 7, time: 2622.176s, loss: 0.743, train accuracy: 0.656\n",
      "epoch: 7, time: 2626.317s, loss: 0.689, train accuracy: 0.812\n",
      "epoch: 7, time: 2630.460s, loss: 1.160, train accuracy: 0.594\n",
      "epoch: 7, time: 2634.604s, loss: 0.673, train accuracy: 0.750\n",
      "epoch: 7, time: 2638.748s, loss: 0.441, train accuracy: 0.781\n",
      "epoch: 7, time: 2642.893s, loss: 0.754, train accuracy: 0.719\n",
      "epoch: 7, time: 2647.036s, loss: 0.642, train accuracy: 0.750\n",
      "epoch: 7, time: 2651.184s, loss: 0.664, train accuracy: 0.781\n",
      "epoch: 7, time: 2655.325s, loss: 0.627, train accuracy: 0.844\n",
      "epoch: 7, time: 2659.470s, loss: 1.034, train accuracy: 0.625\n",
      "epoch: 7, time: 2663.616s, loss: 0.549, train accuracy: 0.812\n",
      "epoch: 7, time: 2667.773s, loss: 0.858, train accuracy: 0.656\n",
      "epoch: 7, time: 2671.918s, loss: 0.651, train accuracy: 0.688\n",
      "epoch: 7, time: 2676.074s, loss: 0.650, train accuracy: 0.781\n",
      "epoch: 7, time: 2680.224s, loss: 0.847, train accuracy: 0.719\n",
      "epoch: 7, time: 2684.374s, loss: 0.921, train accuracy: 0.750\n",
      "epoch: 7, time: 2688.515s, loss: 0.747, train accuracy: 0.688\n",
      "epoch: 7, time: 2692.664s, loss: 0.458, train accuracy: 0.812\n",
      "epoch: 7, time: 2696.809s, loss: 0.951, train accuracy: 0.688\n",
      "epoch: 7, time: 2700.951s, loss: 0.636, train accuracy: 0.812\n",
      "epoch: 7, time: 2705.106s, loss: 0.716, train accuracy: 0.781\n",
      "epoch: 7, time: 2709.256s, loss: 0.420, train accuracy: 0.781\n",
      "epoch: 7, time: 2713.421s, loss: 0.882, train accuracy: 0.688\n",
      "epoch: 7, time: 2717.587s, loss: 0.232, train accuracy: 0.938\n",
      "epoch: 7, time: 2721.733s, loss: 0.452, train accuracy: 0.812\n",
      "epoch: 7, time: 2725.874s, loss: 0.601, train accuracy: 0.719\n",
      "epoch: 7, time: 2730.019s, loss: 0.787, train accuracy: 0.625\n",
      "epoch: 7, time: 2734.166s, loss: 0.501, train accuracy: 0.812\n",
      "Accuracy on the test set: 0.791\n",
      "epoch: 8, time: 2756.028s, loss: 0.390, train accuracy: 0.844\n",
      "epoch: 8, time: 2760.195s, loss: 0.635, train accuracy: 0.812\n",
      "epoch: 8, time: 2764.289s, loss: 0.481, train accuracy: 0.812\n",
      "epoch: 8, time: 2768.380s, loss: 0.622, train accuracy: 0.781\n",
      "epoch: 8, time: 2772.475s, loss: 0.975, train accuracy: 0.688\n",
      "epoch: 8, time: 2776.569s, loss: 0.514, train accuracy: 0.781\n",
      "epoch: 8, time: 2780.663s, loss: 0.484, train accuracy: 0.781\n",
      "epoch: 8, time: 2784.762s, loss: 0.784, train accuracy: 0.719\n",
      "epoch: 8, time: 2788.859s, loss: 0.931, train accuracy: 0.688\n",
      "epoch: 8, time: 2793.172s, loss: 0.880, train accuracy: 0.688\n",
      "epoch: 8, time: 2797.350s, loss: 0.570, train accuracy: 0.844\n",
      "epoch: 8, time: 2801.505s, loss: 0.701, train accuracy: 0.781\n",
      "epoch: 8, time: 2805.658s, loss: 0.634, train accuracy: 0.781\n",
      "epoch: 8, time: 2809.826s, loss: 0.395, train accuracy: 0.844\n",
      "epoch: 8, time: 2813.985s, loss: 0.599, train accuracy: 0.750\n",
      "epoch: 8, time: 2818.141s, loss: 0.425, train accuracy: 0.875\n",
      "epoch: 8, time: 2822.320s, loss: 0.370, train accuracy: 0.906\n",
      "epoch: 8, time: 2826.475s, loss: 0.587, train accuracy: 0.875\n",
      "epoch: 8, time: 2830.628s, loss: 0.791, train accuracy: 0.750\n",
      "epoch: 8, time: 2834.790s, loss: 0.628, train accuracy: 0.844\n",
      "epoch: 8, time: 2838.948s, loss: 0.711, train accuracy: 0.750\n",
      "epoch: 8, time: 2843.103s, loss: 0.714, train accuracy: 0.625\n",
      "epoch: 8, time: 2847.265s, loss: 0.616, train accuracy: 0.750\n",
      "epoch: 8, time: 2851.424s, loss: 0.760, train accuracy: 0.781\n",
      "epoch: 8, time: 2855.586s, loss: 1.004, train accuracy: 0.594\n",
      "epoch: 8, time: 2859.740s, loss: 0.681, train accuracy: 0.812\n",
      "epoch: 8, time: 2863.901s, loss: 0.373, train accuracy: 0.906\n",
      "epoch: 8, time: 2868.055s, loss: 0.699, train accuracy: 0.812\n",
      "epoch: 8, time: 2872.214s, loss: 0.423, train accuracy: 0.875\n",
      "epoch: 8, time: 2876.400s, loss: 0.422, train accuracy: 0.906\n",
      "epoch: 8, time: 2880.560s, loss: 0.566, train accuracy: 0.812\n",
      "epoch: 8, time: 2884.716s, loss: 0.729, train accuracy: 0.812\n",
      "epoch: 8, time: 2888.891s, loss: 0.648, train accuracy: 0.719\n",
      "epoch: 8, time: 2893.051s, loss: 0.399, train accuracy: 0.844\n",
      "epoch: 8, time: 2897.206s, loss: 0.423, train accuracy: 0.875\n",
      "epoch: 8, time: 2901.368s, loss: 0.427, train accuracy: 0.875\n",
      "epoch: 8, time: 2905.525s, loss: 0.474, train accuracy: 0.844\n",
      "epoch: 8, time: 2909.679s, loss: 0.255, train accuracy: 0.938\n",
      "epoch: 8, time: 2913.842s, loss: 0.476, train accuracy: 0.812\n",
      "epoch: 8, time: 2918.003s, loss: 0.410, train accuracy: 0.906\n",
      "epoch: 8, time: 2922.154s, loss: 0.518, train accuracy: 0.812\n",
      "epoch: 8, time: 2926.320s, loss: 0.867, train accuracy: 0.719\n",
      "epoch: 8, time: 2930.474s, loss: 0.840, train accuracy: 0.719\n",
      "epoch: 8, time: 2934.626s, loss: 0.609, train accuracy: 0.812\n",
      "epoch: 8, time: 2938.779s, loss: 0.410, train accuracy: 0.875\n",
      "epoch: 8, time: 2942.940s, loss: 0.956, train accuracy: 0.688\n",
      "epoch: 8, time: 2947.095s, loss: 0.423, train accuracy: 0.812\n",
      "epoch: 8, time: 2951.251s, loss: 0.496, train accuracy: 0.844\n",
      "epoch: 8, time: 2955.410s, loss: 0.735, train accuracy: 0.656\n",
      "epoch: 8, time: 2959.566s, loss: 1.146, train accuracy: 0.531\n",
      "epoch: 8, time: 2963.724s, loss: 1.187, train accuracy: 0.656\n",
      "epoch: 8, time: 2967.879s, loss: 0.262, train accuracy: 0.906\n",
      "epoch: 8, time: 2972.034s, loss: 0.980, train accuracy: 0.688\n",
      "epoch: 8, time: 2976.203s, loss: 0.411, train accuracy: 0.844\n",
      "epoch: 8, time: 2980.359s, loss: 0.861, train accuracy: 0.781\n",
      "epoch: 8, time: 2984.514s, loss: 0.768, train accuracy: 0.750\n",
      "epoch: 8, time: 2988.665s, loss: 0.446, train accuracy: 0.844\n",
      "epoch: 8, time: 2992.823s, loss: 0.467, train accuracy: 0.844\n",
      "epoch: 8, time: 2996.977s, loss: 0.398, train accuracy: 0.875\n",
      "epoch: 8, time: 3001.130s, loss: 0.687, train accuracy: 0.750\n",
      "epoch: 8, time: 3005.294s, loss: 0.621, train accuracy: 0.719\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0jcJkRe8T7BW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "correct_total = 0\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "  y_pred = net(x_batch)\n",
    "  y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V4RSHW_QT6Ls",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rmaaXUzTT6Ix",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0cbLSRfqT6F3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}